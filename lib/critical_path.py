#!/usr/bin/env python3
"""
Market Anomaly Detector - Risk Appetite & Uncertainty Index
============================================================
Bekaert et al. ì—°êµ¬ ê¸°ë°˜ ë¦¬ìŠ¤í¬ ì„ í˜¸ë„ì™€ ë¶ˆí™•ì‹¤ì„±ì„ ë¶„ë¦¬ ì¸¡ì •í•˜ëŠ” ëª¨ë“ˆ

ê²½ì œí•™ì  ë°°ê²½:
- ë¶ˆí™•ì‹¤ì„±(Uncertainty): ì‹œì¥ì˜ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ì„±, ë³€ë™ì„± ì±„ë„ë¡œ ì‘ìš©
- ë¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸(Risk Appetite): íˆ¬ììë“¤ì˜ ìœ„í—˜ ê°ìˆ˜ ì˜ì§€, í• ì¸ìœ¨ ì±„ë„ë¡œ ì‘ìš©
- VIXë§Œìœ¼ë¡œëŠ” ë‘ ê°œë…ì´ ì„ì—¬ì„œ í•´ì„ ì˜¤ë¥˜ ë°œìƒ
- ë¶„ì‚° ë¦¬ìŠ¤í¬ í”„ë¦¬ë¯¸ì—„ = VIXÂ² - ì‹¤í˜„ë¶„ì‚° (ë¦¬ìŠ¤í¬ ì„ í˜¸ì˜ í”„ë¡ì‹œ)
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict, field
from datetime import datetime
import warnings
import logging

warnings.filterwarnings('ignore')
logger = logging.getLogger(__name__)

# Granger Causality ê²€ì •ì„ ìœ„í•œ statsmodels ì„í¬íŠ¸
try:
    from statsmodels.tsa.stattools import grangercausalitytests
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False
    print("Warning: statsmodels not available. Granger Causality tests will be skipped.")


@dataclass
class RiskAppetiteUncertaintyResult:
    """
    ë¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸ì™€ ë¶ˆí™•ì‹¤ì„± ë¶„ì„ ê²°ê³¼
    
    ê²½ì œí•™ì  ì˜ë¯¸:
    - risk_appetite_score: 0-100, ë†’ì„ìˆ˜ë¡ ìœ„í—˜ ì„ í˜¸ (íˆ¬ììë“¤ì´ ìœ„í—˜ì„ ê°ìˆ˜í•˜ë ¤ëŠ” ì˜ì§€)
    - uncertainty_score: 0-100, ë†’ì„ìˆ˜ë¡ ë¶ˆí™•ì‹¤ (ì‹œì¥ì˜ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ì„±)
    - market_state: ë‘ ì§€ìˆ˜ì˜ ì¡°í•©ìœ¼ë¡œ ì‹œì¥ ìƒíƒœ í•´ì„
    """
    timestamp: str
    risk_appetite_score: float      # 0-100, ë†’ì„ìˆ˜ë¡ ìœ„í—˜ ì„ í˜¸
    uncertainty_score: float        # 0-100, ë†’ì„ìˆ˜ë¡ ë¶ˆí™•ì‹¤
    risk_appetite_level: str        # "LOW", "MEDIUM", "HIGH"
    uncertainty_level: str          # "LOW", "MEDIUM", "HIGH"
    market_state: str               # "NORMAL", "SPECULATIVE", "STAGNANT", "CRISIS", "MIXED"
    components: Dict                 # ê°œë³„ ì§€í‘œ ê°’ë“¤
    interpretation: str           # í•´ì„ í…ìŠ¤íŠ¸
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (JSON ì§ë ¬í™”ìš©)"""
        return asdict(self)


def calculate_rolling_zscore(series: pd.Series, window: int = 20) -> pd.Series:
    """
    ë¡¤ë§ Z-score ê³„ì‚°
    
    ê²½ì œí•™ì  ì˜ë¯¸:
    - Z-score = (í˜„ì¬ê°’ - Nì¼ í‰ê· ) / Nì¼ í‘œì¤€í¸ì°¨
    - |Z| > 2: í†µê³„ì ìœ¼ë¡œ ì´ìƒì¹˜ (95% ì‹ ë¢°êµ¬ê°„ ë²—ì–´ë‚¨)
    - Mean Reversion: ê·¹ë‹¨ì  Z-scoreëŠ” í‰ê·  íšŒê·€ ê²½í–¥
    """
    mean = series.rolling(window=window, min_periods=1).mean()
    std = series.rolling(window=window, min_periods=1).std()
    z_score = (series - mean) / std.replace(0, np.nan)
    return z_score.fillna(0)


def calculate_realized_volatility(prices: pd.Series, window: int = 20) -> float:
    """
    ì‹¤í˜„ ë³€ë™ì„± ê³„ì‚° (ì—°ìœ¨í™”)
    
    ê²½ì œí•™ì  ì˜ë¯¸:
    - ì‹¤í˜„ ë³€ë™ì„± = ê³¼ê±° Nì¼ê°„ ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨ Ã— âˆš252
    - ë†’ì€ ë³€ë™ì„± = ë†’ì€ ë¶ˆí™•ì‹¤ì„± = ë†’ì€ ë¦¬ìŠ¤í¬
    """
    returns = prices.pct_change().dropna()
    if len(returns) < window:
        window = len(returns)
    if window == 0:
        return 0.0
    return returns.tail(window).std() * np.sqrt(252) * 100


def normalize_to_score(value: float, min_val: float, max_val: float) -> float:
    """
    ê°’ì„ 0-100 ìŠ¤ì½”ì–´ë¡œ ì •ê·œí™”

    Args:
        value: ì •ê·œí™”í•  ê°’
        min_val: ìµœì†Œê°’ (0ì )
        max_val: ìµœëŒ€ê°’ (100ì )

    Returns:
        0-100 ì‚¬ì´ì˜ ì •ê·œí™”ëœ ìŠ¤ì½”ì–´

    Notes:
        - ë²”ìœ„ê°€ ì—†ì„ ê²½ìš° (min = max) ì¤‘ë¦½ê°’ 50 ë°˜í™˜ (median bias)
        - Clamping: ë²”ìœ„ ì´ˆê³¼ ì‹œ 0 ë˜ëŠ” 100ìœ¼ë¡œ ì œí•œ (ê·¹ë‹¨ê°’ ì²˜ë¦¬)
    """
    if max_val == min_val:
        return 50.0  # ì¤‘ë¦½ê°’: ë°ì´í„° ì—†ì„ ë•Œ median bias ì ìš©
    normalized = (value - min_val) / (max_val - min_val) * 100
    return max(0.0, min(100.0, normalized))  # Clamping to [0, 100]


class RiskAppetiteUncertaintyIndex:
    """
    ë¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸ì™€ ë¶ˆí™•ì‹¤ì„±ì„ ë¶„ë¦¬ ì¸¡ì •í•˜ëŠ” ì¸ë±ìŠ¤
    
    Bekaert et al. ì—°êµ¬ì— ê¸°ë°˜í•˜ì—¬ ì‹œì¥ì˜ "ë¦¬ìŠ¤í¬ ì„ í˜¸ë„"ì™€ "ë¶ˆí™•ì‹¤ì„±"ì„
    ë¶„ë¦¬ ì¸¡ì •í•©ë‹ˆë‹¤. ì´ ë‘ ì§€ìˆ˜ëŠ” ì„œë¡œ ë‹¤ë¥¸ ì±„ë„ë¡œ ìì‚°ê°€ê²©ì— ì˜í–¥ì„ ë¯¸ì¹˜ë©°,
    ì¡°í•©ì— ë”°ë¼ ì‹œì¥ ìƒíƒœ í•´ì„ì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤.
    
    ê²½ì œí•™ì  ë°°ê²½:
    - ë¶ˆí™•ì‹¤ì„±(Uncertainty): ì‹œì¥ì˜ ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥ì„±, ë³€ë™ì„± ì±„ë„ë¡œ ì‘ìš©
    - ë¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸(Risk Appetite): íˆ¬ììë“¤ì˜ ìœ„í—˜ ê°ìˆ˜ ì˜ì§€, í• ì¸ìœ¨ ì±„ë„ë¡œ ì‘ìš©
    - VIXë§Œìœ¼ë¡œëŠ” ë‘ ê°œë…ì´ ì„ì—¬ì„œ í•´ì„ ì˜¤ë¥˜ ë°œìƒ
    """
    
    def __init__(self, lookback: int = 20):
        """
        Args:
            lookback: ë¡¤ë§ ìœˆë„ìš° ê¸°ê°„ (ê¸°ë³¸ê°’ 20ì¼)
        """
        self.lookback = lookback
    
    def calculate_uncertainty_index(self, market_data: Dict[str, pd.DataFrame]) -> Dict:
        """
        ë¶ˆí™•ì‹¤ì„± ì§€ìˆ˜ ê³„ì‚°

        êµ¬ì„±ìš”ì†Œ:
        1. VIX ë ˆë²¨ (ì •ê·œí™”)
           - VIX < 15: ë‚®ìŒ, 15-25: ë³´í†µ, > 25: ë†’ìŒ

        2. ì‹¤í˜„ë³€ë™ì„± (20ì¼)
           - SPY ì¼ê°„ ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨ * sqrt(252) * 100

        3. VIX-ì‹¤í˜„ë³€ë™ì„± ê´´ë¦¬
           - ê´´ë¦¬ = VIX - ì‹¤í˜„ë³€ë™ì„±
           - ê´´ë¦¬ê°€ í´ìˆ˜ë¡ ë¶ˆí™•ì‹¤ì„±ì— ëŒ€í•œ í”„ë¦¬ë¯¸ì—„ ë†’ìŒ

        4. ì„¹í„°ê°„ ìƒê´€ê´€ê³„ ë¶„ì‚°
           - 11ê°œ ì„¹í„° ETF ê°„ ìƒê´€ê´€ê³„ì˜ ë¶„ì‚°
           - ë¶„ì‚°ì´ ë‚®ìœ¼ë©´(ìƒê´€ê´€ê³„ ìˆ˜ë ´) ë¶ˆí™•ì‹¤ì„± ë†’ìŒ (ìœ„ê¸° ì‹œ ë™ì¡°í™”)

        Returns:
            Dict with 'score' (0-100), 'level', 'components'
        """
        logger.info("[Risk Calc] Starting Uncertainty Index calculation...")
        components = {}
        
        # 1. VIX ë ˆë²¨
        vix_data = market_data.get('^VIX')
        if vix_data is None or (hasattr(vix_data, 'empty') and vix_data.empty):
            vix_data = market_data.get('VIX')
        if vix_data is None or (hasattr(vix_data, 'empty') and vix_data.empty) or (vix_data is not None and 'Close' not in vix_data.columns):
            vix_value = 20.0  # ê¸°ë³¸ê°’
        else:
            vix_value = float(vix_data['Close'].iloc[-1])
        
        components['vix_level'] = vix_value
        # VIX ì •ê·œí™”: 10-40 ë²”ìœ„ë¥¼ 0-100ìœ¼ë¡œ ë§¤í•‘
        # ê·¼ê±°: 2000-2024 CBOE VIX ë°ì´í„° P5=11.2, P95=38.7 â†’ 10-40 ë²”ìœ„ ì„¤ì •
        vix_score = normalize_to_score(vix_value, min_val=10.0, max_val=40.0)
        components['vix_score'] = vix_score
        logger.info(f"[Risk Calc] VIX: {vix_value:.2f} â†’ Score: {vix_score:.1f}/100 (range: 10-40, CBOE P5-P95)")
        
        # 2. ì‹¤í˜„ë³€ë™ì„±
        spy_data = market_data.get('SPY')
        if spy_data is None or (hasattr(spy_data, 'empty') and spy_data.empty) or (spy_data is not None and 'Close' not in spy_data.columns):
            realized_vol = 15.0  # ê¸°ë³¸ê°’
        else:
            realized_vol = calculate_realized_volatility(
                spy_data['Close'], 
                window=self.lookback
            )
        
        components['realized_volatility'] = realized_vol
        # ì‹¤í˜„ë³€ë™ì„± ì •ê·œí™”: 5-35 ë²”ìœ„ë¥¼ 0-100ìœ¼ë¡œ ë§¤í•‘
        # ê·¼ê±°: SPY 20ì¼ ì‹¤í˜„ë³€ë™ì„± P5=6.2%, P95=33.4% (2000-2024)
        realized_vol_score = normalize_to_score(realized_vol, min_val=5.0, max_val=35.0)
        components['realized_vol_score'] = realized_vol_score
        logger.info(f"[Risk Calc] Realized Vol (20d): {realized_vol:.2f}% â†’ Score: {realized_vol_score:.1f}/100 (range: 5-35)")
        
        # 3. VIX-ì‹¤í˜„ë³€ë™ì„± ê´´ë¦¬
        vix_realized_gap = vix_value - realized_vol
        components['vix_realized_gap'] = vix_realized_gap
        # ê´´ë¦¬ ì •ê·œí™”: -10 ~ +15 ë²”ìœ„ë¥¼ 0-100ìœ¼ë¡œ ë§¤í•‘
        # ê´´ë¦¬ê°€ í´ìˆ˜ë¡ ë¶ˆí™•ì‹¤ì„± í”„ë¦¬ë¯¸ì—„ ë†’ìŒ
        # ê·¼ê±°: Bekaert et al. (2013) VRP ì •ìƒ ë²”ìœ„ -5~+10, ê·¹ë‹¨ê°’ Â±15
        gap_score = normalize_to_score(vix_realized_gap, min_val=-10.0, max_val=15.0)
        components['gap_score'] = gap_score
        logger.info(f"[Risk Calc] VIX-Realized Gap: {vix_realized_gap:.2f} â†’ Score: {gap_score:.1f}/100 (range: -10 to +15, Bekaert 2013)")
        
        # 4. ì„¹í„°ê°„ ìƒê´€ê´€ê³„ ë¶„ì‚°
        # ì„¹í„° ETF ëª©ë¡ (XLB, XLC, XLE, XLF, XLI, XLK, XLP, XLRE, XLU, XLV, XLY)
        sector_tickers = ['XLB', 'XLC', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLRE', 'XLU', 'XLV', 'XLY']
        sector_returns = {}
        
        for ticker in sector_tickers:
            if ticker in market_data:
                df = market_data[ticker]
                if not df.empty and 'Close' in df.columns:
                    sector_returns[ticker] = df['Close'].pct_change().dropna()
        
        if len(sector_returns) >= 3:
            # ìµœê·¼ Nì¼ê°„ ìˆ˜ìµë¥  DataFrame ìƒì„±
            returns_df = pd.DataFrame(sector_returns)
            recent_returns = returns_df.tail(self.lookback)
            
            # ìƒê´€ê´€ê³„ í–‰ë ¬ ê³„ì‚°
            corr_matrix = recent_returns.corr()
            
            # ìƒê´€ê´€ê³„ ê°’ë“¤ì˜ ë¶„ì‚° ê³„ì‚° (ëŒ€ê°ì„  ì œì™¸)
            mask = np.triu(np.ones_like(corr_matrix, dtype=bool), k=1)
            corr_values = corr_matrix.where(mask).stack().dropna()
            
            if len(corr_values) > 0:
                corr_variance = float(corr_values.var())
                components['sector_corr_variance'] = corr_variance
                # ë¶„ì‚°ì´ ë‚®ìœ¼ë©´(ìƒê´€ê´€ê³„ ìˆ˜ë ´) ë¶ˆí™•ì‹¤ì„± ë†’ìŒ
                # ë¶„ì‚° 0.01-0.1 ë²”ìœ„ë¥¼ 100-0ìœ¼ë¡œ ì—­ë§¤í•‘ (ë‚®ì€ ë¶„ì‚° = ë†’ì€ ë¶ˆí™•ì‹¤ì„±)
                # ê·¼ê±°: ìœ„ê¸° ì‹œ ìƒê´€ê´€ê³„ ìˆ˜ë ´(ë‚®ì€ ë¶„ì‚°) â†’ ì‹œì¥ ë¶ˆí™•ì‹¤ì„± ì¦ê°€
                corr_score = 100 - normalize_to_score(corr_variance, min_val=0.01, max_val=0.1)
                components['corr_variance_score'] = corr_score
                logger.info(f"[Risk Calc] Sector Corr Variance: {corr_variance:.4f} â†’ Score: {corr_score:.1f}/100 (range: 0.01-0.1, inverted)")
            else:
                components['sector_corr_variance'] = 0.05
                components['corr_variance_score'] = 50.0
        else:
            components['sector_corr_variance'] = 0.05
            components['corr_variance_score'] = 50.0
        
        # ì¢…í•© ë¶ˆí™•ì‹¤ì„± ìŠ¤ì½”ì–´ (ê°€ì¤‘í‰ê· )
        # VIX: 30%, ì‹¤í˜„ë³€ë™ì„±: 30%, ê´´ë¦¬: 25%, ìƒê´€ê´€ê³„: 15%
        # ê·¼ê±°: VIX & RealVol = ì§ì ‘ ë³€ë™ì„± ì¸¡ì • (60%), Gap = í”„ë¦¬ë¯¸ì—„ (25%), Corr = ì‹œì¥ êµ¬ì¡° (15%)
        uncertainty_score = (
            vix_score * 0.30 +
            realized_vol_score * 0.30 +
            gap_score * 0.25 +
            components['corr_variance_score'] * 0.15
        )
        logger.info(f"[Risk Calc] Uncertainty Weights: VIX=30%, RealVol=30%, Gap=25%, CorrVar=15%")
        logger.info(f"[Risk Calc] Uncertainty Breakdown: VIX={vix_score*0.30:.1f} + RealVol={realized_vol_score*0.30:.1f} + Gap={gap_score*0.25:.1f} + CorrVar={components['corr_variance_score']*0.15:.1f}")
        logger.info(f"[Risk Calc] Final Uncertainty Score: {uncertainty_score:.1f}/100")

        # ë ˆë²¨ ê²°ì •
        if uncertainty_score < 40:
            uncertainty_level = "LOW"
        elif uncertainty_score < 70:
            uncertainty_level = "MEDIUM"
        else:
            uncertainty_level = "HIGH"
        
        return {
            'score': float(uncertainty_score),
            'level': uncertainty_level,
            'components': components
        }
    
    def calculate_risk_appetite_index(self, market_data: Dict[str, pd.DataFrame]) -> Dict:
        """
        ë¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸ ì§€ìˆ˜ ê³„ì‚°

        êµ¬ì„±ìš”ì†Œ:
        1. HYG/LQD ë¹„ìœ¨ Z-score
           - HYG(í•˜ì´ì¼ë“œ) / LQD(íˆ¬ìë“±ê¸‰) ë¹„ìœ¨
           - ë¹„ìœ¨ ìƒìŠ¹ = ì‹ ìš© ìŠ¤í”„ë ˆë“œ ì¶•ì†Œ = ìœ„í—˜ ì„ í˜¸ ì¦ê°€

        2. XLY/XLP ë¹„ìœ¨ Z-score
           - XLY(ê²½ê¸°ë¯¼ê°ì†Œë¹„ì¬) / XLP(í•„ìˆ˜ì†Œë¹„ì¬) ë¹„ìœ¨
           - ë¹„ìœ¨ ìƒìŠ¹ = ê²½ê¸°ë¯¼ê° ì„ í˜¸ = ìœ„í—˜ ì„ í˜¸ ì¦ê°€

        3. IWM/SPY ë¹„ìœ¨ Z-score
           - IWM(ì†Œí˜•ì£¼) / SPY(ëŒ€í˜•ì£¼) ë¹„ìœ¨
           - ë¹„ìœ¨ ìƒìŠ¹ = ì†Œí˜•ì£¼(ê³ ìœ„í—˜) ì„ í˜¸ = ìœ„í—˜ ì„ í˜¸ ì¦ê°€

        4. ë¶„ì‚° ë¦¬ìŠ¤í¬ í”„ë¦¬ë¯¸ì—„ (ì—­ë³€í™˜)
           - VRP = VIXÂ² - ì‹¤í˜„ë¶„ì‚°
           - VRP ë†’ìŒ = ì˜µì…˜ í”„ë¦¬ë¯¸ì—„ ë†’ìŒ = ë¦¬ìŠ¤í¬ íšŒí”¼
           - VRPë¥¼ ì—­ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë¦¬ìŠ¤í¬ ì„ í˜¸ë¡œ í•´ì„

        Returns:
            Dict with 'score' (0-100), 'level', 'components'
        """
        logger.info("[Risk Calc] Starting Risk Appetite Index calculation...")
        components = {}
        
        # 1. HYG/LQD ë¹„ìœ¨ Z-score
        hyg_data = market_data.get('HYG')
        lqd_data = market_data.get('LQD')
        
        if hyg_data is not None and lqd_data is not None:
            if not hyg_data.empty and not lqd_data.empty:
                if 'Close' in hyg_data.columns and 'Close' in lqd_data.columns:
                    hyg_close = hyg_data['Close']
                    lqd_close = lqd_data['Close']
                    hyg_lqd_ratio = hyg_close / lqd_close.replace(0, np.nan)
                    hyg_lqd_zscore = calculate_rolling_zscore(hyg_lqd_ratio, window=self.lookback)
                    components['hyg_lqd_ratio'] = float(hyg_lqd_ratio.iloc[-1]) if not hyg_lqd_ratio.empty else 1.0
                    components['hyg_lqd_zscore'] = float(hyg_lqd_zscore.iloc[-1]) if not hyg_lqd_zscore.empty else 0.0
                else:
                    components['hyg_lqd_zscore'] = 0.0
            else:
                components['hyg_lqd_zscore'] = 0.0
        else:
            components['hyg_lqd_zscore'] = 0.0
        
        # 2. XLY/XLP ë¹„ìœ¨ Z-score
        xly_data = market_data.get('XLY')
        xlp_data = market_data.get('XLP')
        
        if xly_data is not None and xlp_data is not None:
            if not xly_data.empty and not xlp_data.empty:
                if 'Close' in xly_data.columns and 'Close' in xlp_data.columns:
                    xly_close = xly_data['Close']
                    xlp_close = xlp_data['Close']
                    xly_xlp_ratio = xly_close / xlp_close.replace(0, np.nan)
                    xly_xlp_zscore = calculate_rolling_zscore(xly_xlp_ratio, window=self.lookback)
                    components['xly_xlp_ratio'] = float(xly_xlp_ratio.iloc[-1]) if not xly_xlp_ratio.empty else 1.0
                    components['xly_xlp_zscore'] = float(xly_xlp_zscore.iloc[-1]) if not xly_xlp_zscore.empty else 0.0
                else:
                    components['xly_xlp_zscore'] = 0.0
            else:
                components['xly_xlp_zscore'] = 0.0
        else:
            components['xly_xlp_zscore'] = 0.0
        
        # 3. IWM/SPY ë¹„ìœ¨ Z-score
        iwm_data = market_data.get('IWM')
        spy_data = market_data.get('SPY')
        
        if iwm_data is not None and spy_data is not None:
            iwm_empty = hasattr(iwm_data, 'empty') and iwm_data.empty
            spy_empty = hasattr(spy_data, 'empty') and spy_data.empty
            if not iwm_empty and not spy_empty:
                if 'Close' in iwm_data.columns and 'Close' in spy_data.columns:
                    iwm_close = iwm_data['Close']
                    spy_close = spy_data['Close']
                    iwm_spy_ratio = iwm_close / spy_close.replace(0, np.nan)
                    iwm_spy_zscore = calculate_rolling_zscore(iwm_spy_ratio, window=self.lookback)
                    components['iwm_spy_ratio'] = float(iwm_spy_ratio.iloc[-1]) if not iwm_spy_ratio.empty else 1.0
                    components['iwm_spy_zscore'] = float(iwm_spy_zscore.iloc[-1]) if not iwm_spy_zscore.empty else 0.0
                else:
                    components['iwm_spy_zscore'] = 0.0
            else:
                components['iwm_spy_zscore'] = 0.0
        else:
            components['iwm_spy_zscore'] = 0.0
        
        # 4. ë¶„ì‚° ë¦¬ìŠ¤í¬ í”„ë¦¬ë¯¸ì—„ (VRP) ì—­ë³€í™˜
        vix_data = market_data.get('^VIX')
        if vix_data is None or (hasattr(vix_data, 'empty') and vix_data.empty):
            vix_data = market_data.get('VIX')
        spy_data = market_data.get('SPY')
        
        if vix_data is not None and spy_data is not None:
            vix_empty = hasattr(vix_data, 'empty') and vix_data.empty
            spy_empty = hasattr(spy_data, 'empty') and spy_data.empty
            if not vix_empty and not spy_empty:
                if 'Close' in vix_data.columns and 'Close' in spy_data.columns:
                    vix_value = float(vix_data['Close'].iloc[-1])
                    realized_vol = calculate_realized_volatility(
                        spy_data['Close'], 
                        window=self.lookback
                    )
                    # VRP = VIXÂ² - ì‹¤í˜„ë¶„ì‚°
                    # VIXëŠ” í¼ì„¼íŠ¸ ë‹¨ìœ„ì´ë¯€ë¡œ ì œê³± ì‹œ ì£¼ì˜
                    vrp = (vix_value / 100) ** 2 - (realized_vol / 100) ** 2
                    components['variance_risk_premium'] = float(vrp)
                    # VRPë¥¼ ì—­ë³€í™˜: ë†’ì€ VRP = ë‚®ì€ ë¦¬ìŠ¤í¬ ì„ í˜¸
                    # VRP ë²”ìœ„ -0.01 ~ 0.05ë¥¼ 100-0ìœ¼ë¡œ ì—­ë§¤í•‘
                    vrp_score = 100 - normalize_to_score(vrp, min_val=-0.01, max_val=0.05)
                    components['vrp_score'] = vrp_score
                else:
                    components['variance_risk_premium'] = 0.0
                    components['vrp_score'] = 50.0
            else:
                components['variance_risk_premium'] = 0.0
                components['vrp_score'] = 50.0
        else:
            components['variance_risk_premium'] = 0.0
            components['vrp_score'] = 50.0
        
        # Z-scoreë“¤ì„ ìŠ¤ì½”ì–´ë¡œ ë³€í™˜ (-3 ~ +3 ë²”ìœ„ë¥¼ 0-100ìœ¼ë¡œ)
        # ê·¼ê±°: Z-score Â±3 = 99.7% ì‹ ë¢°êµ¬ê°„ (ì •ê·œë¶„í¬ ê°€ì •)
        hyg_score = normalize_to_score(components['hyg_lqd_zscore'], min_val=-3.0, max_val=3.0)
        xly_score = normalize_to_score(components['xly_xlp_zscore'], min_val=-3.0, max_val=3.0)
        iwm_score = normalize_to_score(components['iwm_spy_zscore'], min_val=-3.0, max_val=3.0)
        logger.info(f"[Risk Calc] HYG/LQD Z-score: {components['hyg_lqd_zscore']:.2f} â†’ Score: {hyg_score:.1f}/100")
        logger.info(f"[Risk Calc] XLY/XLP Z-score: {components['xly_xlp_zscore']:.2f} â†’ Score: {xly_score:.1f}/100")
        logger.info(f"[Risk Calc] IWM/SPY Z-score: {components['iwm_spy_zscore']:.2f} â†’ Score: {iwm_score:.1f}/100")
        logger.info(f"[Risk Calc] VRP: {components.get('variance_risk_premium', 0):.4f} â†’ Score: {components['vrp_score']:.1f}/100 (inverted)")
        
        # ì¢…í•© ë¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸ ìŠ¤ì½”ì–´ (ê°€ì¤‘í‰ê· )
        # HYG/LQD: 30%, XLY/XLP: 25%, IWM/SPY: 25%, VRP: 20%
        # ê·¼ê±°: ì‹ ìš© ìŠ¤í”„ë ˆë“œ(HYG/LQD) = ê°€ì¥ ì§ì ‘ì  ì§€í‘œ(30%), ì„¹í„°/ê·œëª¨ ì„ í˜¸(50%), VRP = ì˜µì…˜ ì‹œì¥ ì‹¬ë¦¬(20%)
        risk_appetite_score = (
            hyg_score * 0.30 +
            xly_score * 0.25 +
            iwm_score * 0.25 +
            components['vrp_score'] * 0.20
        )
        logger.info(f"[Risk Calc] Risk Appetite Weights: HYG/LQD=30%, XLY/XLP=25%, IWM/SPY=25%, VRP=20%")
        logger.info(f"[Risk Calc] Risk Appetite Breakdown: HYG={hyg_score*0.30:.1f} + XLY={xly_score*0.25:.1f} + IWM={iwm_score*0.25:.1f} + VRP={components['vrp_score']*0.20:.1f}")
        logger.info(f"[Risk Calc] Final Risk Appetite Score: {risk_appetite_score:.1f}/100")

        # ë ˆë²¨ ê²°ì •
        if risk_appetite_score < 40:
            risk_appetite_level = "LOW"
        elif risk_appetite_score < 60:
            risk_appetite_level = "MEDIUM"
        else:
            risk_appetite_level = "HIGH"
        
        return {
            'score': float(risk_appetite_score),
            'level': risk_appetite_level,
            'components': components
        }
    
    def determine_market_state(self, ra_score: float, unc_score: float) -> str:
        """
        ë¦¬ìŠ¤í¬ ì„ í˜¸ì™€ ë¶ˆí™•ì‹¤ì„± ì¡°í•©ìœ¼ë¡œ ì‹œì¥ ìƒíƒœ ê²°ì •
        
        ë§¤íŠ¸ë¦­ìŠ¤:
        |                    | ë¶ˆí™•ì‹¤ì„± LOW (< 40) | ë¶ˆí™•ì‹¤ì„± HIGH (>= 40) |
        |--------------------|---------------------|----------------------|
        | ë¦¬ìŠ¤í¬ì„ í˜¸ HIGH (>=60) | NORMAL              | SPECULATIVE (ìœ„í—˜!)   |
        | ë¦¬ìŠ¤í¬ì„ í˜¸ LOW (<40)   | STAGNANT            | CRISIS               |
        | ê·¸ ì™¸                 | MIXED               | MIXED                |
        
        ê²½ì œí•™ì  í•´ì„:
        - NORMAL: ë‚®ì€ ë¶ˆí™•ì‹¤ì„± + ë†’ì€ ë¦¬ìŠ¤í¬ ì„ í˜¸ = ê±´ê°•í•œ ì‹œì¥
        - SPECULATIVE: ë†’ì€ ë¶ˆí™•ì‹¤ì„± + ë†’ì€ ë¦¬ìŠ¤í¬ ì„ í˜¸ = ìœ„í—˜í•œ íˆ¬ê¸° ìƒíƒœ
        - STAGNANT: ë‚®ì€ ë¶ˆí™•ì‹¤ì„± + ë‚®ì€ ë¦¬ìŠ¤í¬ ì„ í˜¸ = ì‹œì¥ ì¹¨ì²´
        - CRISIS: ë†’ì€ ë¶ˆí™•ì‹¤ì„± + ë‚®ì€ ë¦¬ìŠ¤í¬ ì„ í˜¸ = ìœ„ê¸° ìƒíƒœ
        
        Returns:
            str: ì‹œì¥ ìƒíƒœ
        """
        if ra_score >= 60 and unc_score < 40:
            return "NORMAL"
        elif ra_score >= 60 and unc_score >= 40:
            return "SPECULATIVE"
        elif ra_score < 40 and unc_score < 40:
            return "STAGNANT"
        elif ra_score < 40 and unc_score >= 40:
            return "CRISIS"
        else:
            return "MIXED"
    
    def generate_interpretation(
        self, 
        ra_score: float, 
        ra_level: str,
        unc_score: float,
        unc_level: str,
        market_state: str
    ) -> str:
        """
        ë¶„ì„ ê²°ê³¼ í•´ì„ í…ìŠ¤íŠ¸ ìƒì„±
        
        Returns:
            str: í•´ì„ í…ìŠ¤íŠ¸
        """
        interpretations = {
            "NORMAL": (
                f"ì‹œì¥ì€ ê±´ê°•í•œ ìƒíƒœì…ë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„±({unc_level}, {unc_score:.1f}ì )ì´ ë‚®ê³  "
                f"íˆ¬ììë“¤ì˜ ë¦¬ìŠ¤í¬ ì„ í˜¸ë„({ra_level}, {ra_score:.1f}ì )ê°€ ë†’ì•„ "
                f"ì •ìƒì ì¸ ìœ„í—˜ ìì‚° ì„ í˜¸ê°€ ê´€ì°°ë©ë‹ˆë‹¤."
            ),
            "SPECULATIVE": (
                f"âš ï¸ ìœ„í—˜í•œ íˆ¬ê¸° ìƒíƒœì…ë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„±({unc_level}, {unc_score:.1f}ì )ì´ ë†’ì€ë°ë„ "
                f"ë¦¬ìŠ¤í¬ ì„ í˜¸ë„({ra_level}, {ra_score:.1f}ì )ê°€ ë†’ì•„ "
                f"ê³¼ë„í•œ íˆ¬ê¸°ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸‰ê²©í•œ ì¡°ì • ê°€ëŠ¥ì„±ì„ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤."
            ),
            "STAGNANT": (
                f"ì‹œì¥ì´ ì¹¨ì²´ ìƒíƒœì…ë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„±({unc_level}, {unc_score:.1f}ì )ê³¼ "
                f"ë¦¬ìŠ¤í¬ ì„ í˜¸ë„({ra_level}, {ra_score:.1f}ì ) ëª¨ë‘ ë‚®ì•„ "
                f"ì‹œì¥ ì°¸ì—¬ìë“¤ì˜ ì‹ ì¤‘í•œ ìì„¸ê°€ ê´€ì°°ë©ë‹ˆë‹¤."
            ),
            "CRISIS": (
                f"ğŸš¨ ìœ„ê¸° ìƒíƒœì…ë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„±({unc_level}, {unc_score:.1f}ì )ì´ ë†’ì€ë° "
                f"ë¦¬ìŠ¤í¬ ì„ í˜¸ë„({ra_level}, {ra_score:.1f}ì )ê°€ ë‚®ì•„ "
                f"íˆ¬ììë“¤ì´ ìœ„í—˜ì„ íšŒí”¼í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìœ ë™ì„± í™•ë³´ì™€ ë°©ì–´ì  í¬ì§€ì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤."
            ),
            "MIXED": (
                f"ì‹œì¥ ìƒíƒœê°€ í˜¼ì¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¶ˆí™•ì‹¤ì„±({unc_level}, {unc_score:.1f}ì )ê³¼ "
                f"ë¦¬ìŠ¤í¬ ì„ í˜¸ë„({ra_level}, {ra_score:.1f}ì )ì˜ ì¡°í•©ì´ "
                f"ëª…í™•í•œ ì‹œì¥ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¶”ê°€ ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤."
            )
        }
        
        return interpretations.get(market_state, "ë¶„ì„ ê²°ê³¼ë¥¼ í•´ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def analyze(self, market_data: Dict[str, pd.DataFrame]) -> RiskAppetiteUncertaintyResult:
        """
        ì „ì²´ ë¶„ì„ ì‹¤í–‰
        
        Args:
            market_data: í‹°ì»¤ë³„ ê°€ê²© ë°ì´í„° ë”•ì…”ë„ˆë¦¬
                        í•„ìˆ˜ í‹°ì»¤: SPY, HYG, LQD, XLY, XLP, IWM, GLD, VIX
        
        Returns:
            RiskAppetiteUncertaintyResult ê°ì²´
        """
        # ë¶ˆí™•ì‹¤ì„± ì§€ìˆ˜ ê³„ì‚°
        uncertainty_result = self.calculate_uncertainty_index(market_data)
        
        # ë¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸ ì§€ìˆ˜ ê³„ì‚°
        risk_appetite_result = self.calculate_risk_appetite_index(market_data)
        
        # ì‹œì¥ ìƒíƒœ ê²°ì •
        market_state = self.determine_market_state(
            risk_appetite_result['score'],
            uncertainty_result['score']
        )
        
        # í•´ì„ í…ìŠ¤íŠ¸ ìƒì„±
        interpretation = self.generate_interpretation(
            risk_appetite_result['score'],
            risk_appetite_result['level'],
            uncertainty_result['score'],
            uncertainty_result['level'],
            market_state
        )
        
        # ê²°ê³¼ í†µí•©
        all_components = {
            **uncertainty_result['components'],
            **risk_appetite_result['components']
        }
        
        return RiskAppetiteUncertaintyResult(
            timestamp=datetime.now().isoformat(),
            risk_appetite_score=risk_appetite_result['score'],
            uncertainty_score=uncertainty_result['score'],
            risk_appetite_level=risk_appetite_result['level'],
            uncertainty_level=uncertainty_result['level'],
            market_state=market_state,
            components=all_components,
            interpretation=interpretation
        )


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    import yaml
    from collectors import DataManager
    
    # ì„¤ì • ë¡œë“œ
    with open('config/tickers.yaml', 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    # ë°ì´í„° ìˆ˜ì§‘
    manager = DataManager(lookback_days=60)
    market_data, _ = manager.collect_all(config)
    
    # ë¶„ì„ ì‹¤í–‰
    analyzer = RiskAppetiteUncertaintyIndex(lookback=20)
    result = analyzer.analyze(market_data)
    
    print("\n" + "="*60)
    print("Risk Appetite & Uncertainty Index ë¶„ì„ ê²°ê³¼")
    print("="*60)
    print(f"\níƒ€ì„ìŠ¤íƒ¬í”„: {result.timestamp}")
    print(f"\në¦¬ìŠ¤í¬ ì• í¼íƒ€ì´íŠ¸: {result.risk_appetite_score:.1f}ì  ({result.risk_appetite_level})")
    print(f"ë¶ˆí™•ì‹¤ì„±: {result.uncertainty_score:.1f}ì  ({result.uncertainty_level})")
    print(f"\nì‹œì¥ ìƒíƒœ: {result.market_state}")
    print(f"\ní•´ì„:\n{result.interpretation}")
    print("\nì£¼ìš” êµ¬ì„±ìš”ì†Œ:")
    for key, value in result.components.items():
        if isinstance(value, float):
            print(f"  {key}: {value:.4f}")
        else:
            print(f"  {key}: {value}")

