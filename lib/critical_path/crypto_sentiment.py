#!/usr/bin/env python3
"""
Critical Path - Crypto Sentiment Block
=======================================

ì•”í˜¸í™”í ì‹¬ë¦¬ ì§€í‘œ ë¸”ë¡ ë¶„ì„ ëª¨ë“ˆ

Economic Foundation:
    IMF (2021): "Crypto-Asset Cross-Border Flows"
    State-Dependent Crypto-Equity Correlation Research

    í•µì‹¬ ê°œë…:
    - í¬ë¦½í† ëŠ” State-Dependent (ë ˆì§ë³„ë¡œ ì—­í•  ë³€í™”)
    - Normal ì‹œê¸°: ë¦¬ìŠ¤í¬ ìì‚°ìœ¼ë¡œ ì‘ë™, ì£¼ì‹ê³¼ ì–‘ì˜ ìƒê´€ê´€ê³„
    - Crisis ì‹œê¸°: ì£¼ì‹ê³¼ ë†’ì€ ë™ì¡°í™” (safe haven ì•„ë‹˜)
    - Granger Causality: BTCê°€ ë¦¬ìŠ¤í¬ ì‹ í˜¸ ì„ í–‰í•  ìˆ˜ ìˆìŒ

Classes:
    - CryptoSentimentBlock: ì•”í˜¸í™”í ì‹¬ë¦¬ ë¶„ì„ ë° ì„ í–‰ ì‹ í˜¸ íƒì§€

Returns:
    CryptoSentimentResult: ì‹¬ë¦¬ ì ìˆ˜, ìƒê´€ê´€ê³„ ë ˆì§, ì„ í–‰ ì‹ í˜¸
"""

import pandas as pd
import numpy as np
from typing import Dict, Optional, Tuple
from datetime import datetime

# Import schemas from same package
from .schemas import CryptoSentimentResult, calculate_rolling_zscore, normalize_to_score

# Check if statsmodels is available
try:
    from statsmodels.tsa.stattools import grangercausalitytests
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False


class CryptoSentimentBlock:
    """
    ì•”í˜¸í™”í ì‹¬ë¦¬ ì§€í‘œ ë¸”ë¡
    
    IMF ì—°êµ¬ ë° State-Dependent ì—°êµ¬ì— ê¸°ë°˜í•˜ì—¬ ì•”í˜¸í™”íë¥¼ ë³„ë„ ë¸”ë¡ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³ ,
    ë ˆì§ì— ë”°ë¼ ë‹¤ë¥´ê²Œ í•´ì„í•©ë‹ˆë‹¤.
    
    ê²½ì œí•™ì  ë°°ê²½:
    - BTC-ì£¼ì‹ ìƒê´€ê´€ê³„ê°€ ë ˆì§ì— ë”°ë¼ ê·¹ì ìœ¼ë¡œ ë‹¤ë¦„
    - í‰ì‹œ: ë‚®ì€ ìƒê´€ê´€ê³„ (0.1-0.3), ë…ìì  ì›€ì§ì„
    - ìœ„ê¸°ì‹œ: ë†’ì€ ìƒê´€ê´€ê³„ (0.6-0.8), ë™ë°˜ í•˜ë½
    - ì•”í˜¸í™”íê°€ "ìœ ë™ì„±ì˜ ì¹´ë‚˜ë¦¬ì•„" ì—­í•  ê°€ëŠ¥ì„± (IMF)
    - BTCâ†’ì£¼ì‹ ë°©í–¥ spilloverê°€ ë°˜ëŒ€ë³´ë‹¤ ê°•í•¨ (íŠ¹íˆ ìœ„ê¸° ì‹œ)
    
    í•µì‹¬ íŠ¹ì§•:
    - í‰ì‹œ/ìœ„ê¸°ì‹œ í•´ì„ì´ ë‹¤ë¦„ (state-dependent)
    - ì„ í–‰ì„± í…ŒìŠ¤íŠ¸ ë‚´ì¥
    - ë ˆì§ì— ë”°ë¼ ì „ì²´ ìœ„í—˜ë„ ê¸°ì—¬ë„ ë³€ë™
    """
    
    # ìƒê´€ê´€ê³„ ê¸°ë°˜ ë ˆì§ ì •ì˜
    CORRELATION_REGIMES = {
        'DECOUPLED': {'min': -0.2, 'max': 0.3},      # ë…ìì  ì›€ì§ì„
        'COUPLED': {'min': 0.3, 'max': 0.6},         # ì—°ë™
        'CRISIS_COUPLED': {'min': 0.6, 'max': 1.0},  # ìœ„ê¸° ë™ì¡°í™”
    }
    
    # ë ˆì§ë³„ ìœ„í—˜ ê¸°ì—¬ë„
    RISK_CONTRIBUTION = {
        'DECOUPLED': 0.05,       # 5% - ë…ì ì‹ í˜¸ë¡œë§Œ í•´ì„
        'COUPLED': 0.10,         # 10%
        'CRISIS_COUPLED': 0.20,  # 20% - ì„ í–‰ì§€í‘œë¡œ ì¤‘ìš”
    }
    
    def __init__(self, lookback: int = 20, correlation_window: int = 20):
        """
        Args:
            lookback: ë¡¤ë§ ìœˆë„ìš° ê¸°ê°„ (ê¸°ë³¸ê°’ 20ì¼)
            correlation_window: ìƒê´€ê´€ê³„ ê³„ì‚° ìœˆë„ìš° (ê¸°ë³¸ê°’ 20ì¼)
        """
        self.lookback = lookback
        self.correlation_window = correlation_window
    
    def calculate_btc_momentum(self, btc_data: pd.DataFrame) -> Dict:
        """
        BTC ëª¨ë©˜í…€ ê³„ì‚°
        
        ì§€í‘œ:
        - 5ì¼ ìˆ˜ìµë¥ 
        - 20ì¼ ìˆ˜ìµë¥ 
        - 5ì¼ MA vs 20ì¼ MA ìœ„ì¹˜
        - ê±°ë˜ëŸ‰ ë³€í™”
        
        Returns:
            Dict with momentum indicators
        """
        if btc_data is None or (hasattr(btc_data, 'empty') and btc_data.empty) or (btc_data is not None and 'Close' not in btc_data.columns):
            return {
                'return_5d': 0.0,
                'return_20d': 0.0,
                'ma5_above_ma20': False,
                'volume_trend': 0.0,
            }
        
        close = btc_data['Close']
        
        # ìˆ˜ìµë¥  ê³„ì‚°
        if len(close) >= 5:
            return_5d = (float(close.iloc[-1]) / float(close.iloc[-5]) - 1) * 100
        else:
            return_5d = 0.0
        
        if len(close) >= 20:
            return_20d = (float(close.iloc[-1]) / float(close.iloc[-20]) - 1) * 100
        else:
            return_20d = 0.0
        
        # ì´ë™í‰ê·  ê³„ì‚°
        ma_5 = close.rolling(window=5, min_periods=1).mean()
        ma_20 = close.rolling(window=20, min_periods=1).mean()
        
        ma5_above_ma20 = False
        if len(ma_5) > 0 and len(ma_20) > 0:
            current_ma5 = float(ma_5.iloc[-1])
            current_ma20 = float(ma_20.iloc[-1])
            ma5_above_ma20 = current_ma5 > current_ma20 if not pd.isna(current_ma5) and not pd.isna(current_ma20) else False
        
        # ê±°ë˜ëŸ‰ ì¶”ì„¸
        volume_trend = 0.0
        if 'Volume' in btc_data.columns and len(btc_data) >= 20:
            volume = btc_data['Volume']
            if len(volume) >= 20:
                recent_volume = float(volume.tail(5).mean()) if len(volume) >= 5 else 0
                avg_volume = float(volume.tail(20).mean())
                if avg_volume > 0:
                    volume_trend = (recent_volume / avg_volume - 1) * 100
        
        return {
            'return_5d': return_5d,
            'return_20d': return_20d,
            'ma5_above_ma20': ma5_above_ma20,
            'volume_trend': volume_trend,
        }
    
    def calculate_btc_spy_correlation(
        self, 
        btc_data: pd.DataFrame,
        spy_data: pd.DataFrame
    ) -> float:
        """
        BTC-SPY ë¡¤ë§ ìƒê´€ê´€ê³„ ê³„ì‚°
        
        Returns:
            float: ìƒê´€ê³„ìˆ˜ (-1 to 1)
        """
        btc_empty = hasattr(btc_data, 'empty') and btc_data.empty if btc_data is not None else True
        spy_empty = hasattr(spy_data, 'empty') and spy_data.empty if spy_data is not None else True
        if btc_empty or spy_empty:
            return 0.0
        
        if 'Close' not in btc_data.columns or 'Close' not in spy_data.columns:
            return 0.0
        
        btc_close = btc_data['Close']
        spy_close = spy_data['Close']
        
        # ì¸ë±ìŠ¤ ì •ë ¬
        common_index = btc_close.index.intersection(spy_close.index)
        if len(common_index) < self.correlation_window:
            return 0.0
        
        # ìµœê·¼ Nì¼ê°„ ìˆ˜ìµë¥  ê³„ì‚°
        btc_returns = btc_close.loc[common_index].pct_change().dropna()
        spy_returns = spy_close.loc[common_index].pct_change().dropna()
        
        # ê³µí†µ ì¸ë±ìŠ¤ë¡œ ì •ë ¬
        common_returns_index = btc_returns.index.intersection(spy_returns.index)
        if len(common_returns_index) < self.correlation_window:
            return 0.0
        
        btc_recent = btc_returns.loc[common_returns_index].tail(self.correlation_window)
        spy_recent = spy_returns.loc[common_returns_index].tail(self.correlation_window)
        
        if len(btc_recent) < self.correlation_window or len(spy_recent) < self.correlation_window:
            return 0.0
        
        # ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation = float(btc_recent.corr(spy_recent))
        
        return correlation if not pd.isna(correlation) else 0.0
    
    def calculate_granger_causality(
        self,
        series_x: pd.Series,  # ì›ì¸ í›„ë³´ ì‹œê³„ì—´ (ì˜ˆ: BTC)
        series_y: pd.Series,  # ê²°ê³¼ í›„ë³´ ì‹œê³„ì—´ (ì˜ˆ: SPY)
        max_lag: int = 5      # ìµœëŒ€ ì‹œì°¨
    ) -> Dict:
        """
        Granger Causality ê²€ì • ìˆ˜í–‰
        
        ê²½ì œí•™ì  ë°°ê²½:
        - Granger(1969): "Xì˜ ê³¼ê±°ê°’ì´ Y ì˜ˆì¸¡ì— ë„ì›€ì´ ë˜ëŠ”ê°€?"
        - ìƒê´€ê´€ê³„ëŠ” ì¸ê³¼ê´€ê³„ê°€ ì•„ë‹˜ (Correlation â‰  Causation)
        - Granger CausalityëŠ” í†µê³„ì  ì¸ê³¼ê´€ê³„ë¥¼ ê²€ì •
        
        Args:
            series_x: ì›ì¸ í›„ë³´ ì‹œê³„ì—´ (ì˜ˆ: BTC ìˆ˜ìµë¥ )
            series_y: ê²°ê³¼ í›„ë³´ ì‹œê³„ì—´ (ì˜ˆ: SPY ìˆ˜ìµë¥ )
            max_lag: ìµœëŒ€ ì‹œì°¨ (ê¸°ë³¸ê°’ 5ì¼)
        
        Returns:
            {
                'x_causes_y': bool,        # Xê°€ Yë¥¼ Granger-causeí•˜ëŠ”ì§€
                'y_causes_x': bool,        # Yê°€ Xë¥¼ Granger-causeí•˜ëŠ”ì§€
                'x_to_y_pvalue': float,    # X->Y ê²€ì •ì˜ p-value
                'y_to_x_pvalue': float,    # Y->X ê²€ì •ì˜ p-value
                'optimal_lag': int,        # ìµœì  ì‹œì°¨
                'relationship': str        # "X_LEADS", "Y_LEADS", "BIDIRECTIONAL", "NO_CAUSALITY"
            }
        """
        if not STATSMODELS_AVAILABLE:
            return {
                'x_causes_y': False,
                'y_causes_x': False,
                'x_to_y_pvalue': 1.0,
                'y_to_x_pvalue': 1.0,
                'optimal_lag': 0,
                'relationship': 'NO_CAUSALITY'
            }
        
        # ë°ì´í„° ì •ë ¬ ë° ì •ê·œí™”
        common_index = series_x.index.intersection(series_y.index)
        if len(common_index) < max_lag + 10:  # ìµœì†Œ ë°ì´í„° ìš”êµ¬ì‚¬í•­
            return {
                'x_causes_y': False,
                'y_causes_x': False,
                'x_to_y_pvalue': 1.0,
                'y_to_x_pvalue': 1.0,
                'optimal_lag': 0,
                'relationship': 'NO_CAUSALITY'
            }
        
        x_aligned = series_x.loc[common_index].dropna()
        y_aligned = series_y.loc[common_index].dropna()
        
        # ê³µí†µ ì¸ë±ìŠ¤ë¡œ ì •ë ¬
        common_idx = x_aligned.index.intersection(y_aligned.index)
        if len(common_idx) < max_lag + 10:
            return {
                'x_causes_y': False,
                'y_causes_x': False,
                'x_to_y_pvalue': 1.0,
                'y_to_x_pvalue': 1.0,
                'optimal_lag': 0,
                'relationship': 'NO_CAUSALITY'
            }
        
        x_data = x_aligned.loc[common_idx].values
        y_data = y_aligned.loc[common_idx].values
        
        # ê²°ì¸¡ê°’ ì œê±°
        valid_mask = ~(np.isnan(x_data) | np.isnan(y_data))
        x_data = x_data[valid_mask]
        y_data = y_data[valid_mask]
        
        if len(x_data) < max_lag + 10 or len(y_data) < max_lag + 10:
            return {
                'x_causes_y': False,
                'y_causes_x': False,
                'x_to_y_pvalue': 1.0,
                'y_to_x_pvalue': 1.0,
                'optimal_lag': 0,
                'relationship': 'NO_CAUSALITY'
            }
        
        # DataFrame ìƒì„± (grangercausalitytestsëŠ” 2ì—´ DataFrame í•„ìš”)
        data_xy = pd.DataFrame({'y': y_data, 'x': x_data})
        data_yx = pd.DataFrame({'x': x_data, 'y': y_data})
        
        # X->Y ê²€ì •
        x_to_y_pvalue = 1.0
        x_causes_y = False
        optimal_lag_xy = 1
        
        try:
            # ê° ì‹œì°¨ë³„ë¡œ ê²€ì •í•˜ê³  ìµœì†Œ p-value ì°¾ê¸°
            min_pvalue_xy = 1.0
            for lag in range(1, min(max_lag + 1, len(data_xy) // 10)):
                try:
                    gc_result = grangercausalitytests(data_xy, maxlag=lag, verbose=False)
                    # grangercausalitytests ë°˜í™˜ê°’: {lag: (test_results_dict, test_statistics)}
                    # test_results_dictì˜ í‚¤: 'ssr_ftest', 'ssr_chi2test', 'lrtest', 'params_ftest'
                    if lag in gc_result:
                        test_results = gc_result[lag][0]
                        # F-test p-value ì¶”ì¶œ
                        if 'ssr_ftest' in test_results:
                            pvalue = test_results['ssr_ftest'][1]  # (F-stat, p-value)
                            if pvalue < min_pvalue_xy:
                                min_pvalue_xy = pvalue
                                optimal_lag_xy = lag
                except (KeyError, IndexError, TypeError, ValueError) as e:
                    # íŠ¹ì • ì‹œì°¨ì—ì„œ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
                    continue
            
            x_to_y_pvalue = min_pvalue_xy
            x_causes_y = x_to_y_pvalue < 0.05  # 5% ìœ ì˜ìˆ˜ì¤€
        except Exception as e:
            # ê²€ì • ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€
            pass
        
        # Y->X ê²€ì •
        y_to_x_pvalue = 1.0
        y_causes_x = False
        optimal_lag_yx = 1
        
        try:
            min_pvalue_yx = 1.0
            for lag in range(1, min(max_lag + 1, len(data_yx) // 10)):
                try:
                    gc_result = grangercausalitytests(data_yx, maxlag=lag, verbose=False)
                    if lag in gc_result:
                        test_results = gc_result[lag][0]
                        if 'ssr_ftest' in test_results:
                            pvalue = test_results['ssr_ftest'][1]
                            if pvalue < min_pvalue_yx:
                                min_pvalue_yx = pvalue
                                optimal_lag_yx = lag
                except (KeyError, IndexError, TypeError, ValueError) as e:
                    continue
            
            y_to_x_pvalue = min_pvalue_yx
            y_causes_x = y_to_x_pvalue < 0.05
        except Exception as e:
            # ê²€ì • ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€
            pass
        
        # ê´€ê³„ ìœ í˜• ê²°ì •
        optimal_lag = max(optimal_lag_xy, optimal_lag_yx)
        
        if x_causes_y and y_causes_x:
            relationship = "BIDIRECTIONAL"
        elif x_causes_y:
            relationship = "X_LEADS"
        elif y_causes_x:
            relationship = "Y_LEADS"
        else:
            relationship = "NO_CAUSALITY"
        
        return {
            'x_causes_y': x_causes_y,
            'y_causes_x': y_causes_x,
            'x_to_y_pvalue': float(x_to_y_pvalue),
            'y_to_x_pvalue': float(y_to_x_pvalue),
            'optimal_lag': optimal_lag,
            'relationship': relationship
        }
    
    def determine_correlation_regime(self, correlation: float) -> str:
        """
        ìƒê´€ê´€ê³„ ê¸°ë°˜ ë ˆì§ íŒë‹¨
        
        Returns:
            str: "DECOUPLED", "COUPLED", "CRISIS_COUPLED"
        """
        for regime, bounds in self.CORRELATION_REGIMES.items():
            if bounds['min'] <= correlation <= bounds['max']:
                return regime
        
        # ê¸°ë³¸ê°’
        if correlation < 0.3:
            return "DECOUPLED"
        elif correlation < 0.6:
            return "COUPLED"
        else:
            return "CRISIS_COUPLED"
    
    def calculate_sentiment_score(self, btc_data: pd.DataFrame) -> Tuple[float, str]:
        """
        ì‹¬ë¦¬ ì ìˆ˜ ê³„ì‚° (Crypto Fear & Greed ìœ ì‚¬ ê°œë…)
        
        êµ¬ì„±ìš”ì†Œ:
        1. ëª¨ë©˜í…€ (40%): 5ì¼/20ì¼ ìˆ˜ìµë¥ 
        2. ë³€ë™ì„± (20%): ìµœê·¼ ë³€ë™ì„± vs í‰ê· 
        3. ê±°ë˜ëŸ‰ (20%): ê±°ë˜ëŸ‰ ì¶”ì„¸
        4. MA ìœ„ì¹˜ (20%): 5MA vs 20MA
        
        Returns:
            Tuple[score (0-100), level]
        
        Level ì •ì˜:
        - 0-20: EXTREME_FEAR
        - 20-40: FEAR
        - 40-60: NEUTRAL
        - 60-80: GREED
        - 80-100: EXTREME_GREED
        """
        if btc_data is None or (hasattr(btc_data, 'empty') and btc_data.empty) or (btc_data is not None and 'Close' not in btc_data.columns):
            return 50.0, "NEUTRAL"
        
        close = btc_data['Close']
        
        # 1. ëª¨ë©˜í…€ ì ìˆ˜ (40%)
        momentum = self.calculate_btc_momentum(btc_data)
        return_5d = momentum['return_5d']
        return_20d = momentum['return_20d']
        
        # 5ì¼ ìˆ˜ìµë¥  ì •ê·œí™” (-10% ~ +10% â†’ 0-100)
        momentum_5d_score = normalize_to_score(return_5d, min_val=-10.0, max_val=10.0)
        # 20ì¼ ìˆ˜ìµë¥  ì •ê·œí™” (-20% ~ +20% â†’ 0-100)
        momentum_20d_score = normalize_to_score(return_20d, min_val=-20.0, max_val=20.0)
        momentum_score = (momentum_5d_score * 0.6 + momentum_20d_score * 0.4) * 0.4
        
        # 2. ë³€ë™ì„± ì ìˆ˜ (20%) - ë‚®ì€ ë³€ë™ì„± = ë†’ì€ ì ìˆ˜ (ì•ˆì •ì )
        if len(close) >= 20:
            returns = close.pct_change().dropna()
            recent_vol = returns.tail(5).std() * np.sqrt(252) * 100 if len(returns) >= 5 else 0
            avg_vol = returns.tail(20).std() * np.sqrt(252) * 100 if len(returns) >= 20 else recent_vol
            
            if avg_vol > 0:
                vol_ratio = recent_vol / avg_vol
                # ë³€ë™ì„±ì´ ë‚®ì„ìˆ˜ë¡ ë†’ì€ ì ìˆ˜ (ì—­ë³€í™˜)
                volatility_score = (2.0 - vol_ratio) / 2.0 * 100 if vol_ratio <= 2.0 else 0
                volatility_score = max(0, min(100, volatility_score)) * 0.2
            else:
                volatility_score = 50.0 * 0.2
        else:
            volatility_score = 50.0 * 0.2
        
        # 3. ê±°ë˜ëŸ‰ ì ìˆ˜ (20%) - ê±°ë˜ëŸ‰ ì¦ê°€ = ë†’ì€ ì ìˆ˜ (ê´€ì‹¬ ì¦ê°€)
        volume_trend = momentum['volume_trend']
        # ê±°ë˜ëŸ‰ ì¶”ì„¸ ì •ê·œí™” (-50% ~ +100% â†’ 0-100)
        volume_score = normalize_to_score(volume_trend, min_val=-50.0, max_val=100.0) * 0.2
        
        # 4. MA ìœ„ì¹˜ ì ìˆ˜ (20%) - 5MA > 20MA = ë†’ì€ ì ìˆ˜
        ma_5 = close.rolling(window=5, min_periods=1).mean()
        ma_20 = close.rolling(window=20, min_periods=1).mean()
        
        ma_score = 50.0
        if len(ma_5) > 0 and len(ma_20) > 0:
            current_ma5 = float(ma_5.iloc[-1])
            current_ma20 = float(ma_20.iloc[-1])
            if not pd.isna(current_ma5) and not pd.isna(current_ma20) and current_ma20 > 0:
                ma_ratio = (current_ma5 / current_ma20 - 1) * 100
                # MA ë¹„ìœ¨ ì •ê·œí™” (-5% ~ +5% â†’ 0-100)
                ma_score = normalize_to_score(ma_ratio, min_val=-5.0, max_val=5.0)
        
        ma_score = ma_score * 0.2
        
        # ì¢…í•© ì ìˆ˜
        total_score = momentum_score + volatility_score + volume_score + ma_score
        total_score = max(0.0, min(100.0, total_score))
        
        # ë ˆë²¨ ê²°ì •
        if total_score < 20:
            level = "EXTREME_FEAR"
        elif total_score < 40:
            level = "FEAR"
        elif total_score < 60:
            level = "NEUTRAL"
        elif total_score < 80:
            level = "GREED"
        else:
            level = "EXTREME_GREED"
        
        return total_score, level
    
    def check_leading_indicator(
        self, 
        btc_data: pd.DataFrame,
        spy_data: pd.DataFrame
    ) -> Tuple[bool, Optional[str]]:
        """
        ì„ í–‰ì§€í‘œ ì—­í•  í…ŒìŠ¤íŠ¸
        
        ì¡°ê±´:
        1. BTCê°€ 5ì¼ê°„ -10% ì´ìƒ í•˜ë½ AND
        2. SPYëŠ” ì•„ì§ -3% ë¯¸ë§Œ í•˜ë½ AND
        3. ìƒê´€ê´€ê³„ê°€ ìƒìŠ¹ ì¶”ì„¸
        â†’ RISK_OFF_WARNING
        
        ë°˜ëŒ€ ì¡°ê±´:
        1. BTCê°€ 5ì¼ê°„ +10% ì´ìƒ ìƒìŠ¹ AND
        2. SPYëŠ” ì•„ì§ +3% ë¯¸ë§Œ ìƒìŠ¹
        â†’ RISK_ON_SIGNAL
        
        Returns:
            Tuple[is_leading, signal_type]
        """
        btc_empty = hasattr(btc_data, 'empty') and btc_data.empty if btc_data is not None else True
        spy_empty = hasattr(spy_data, 'empty') and spy_data.empty if spy_data is not None else True
        if btc_empty or spy_empty:
            return False, None
        
        if 'Close' not in btc_data.columns or 'Close' not in spy_data.columns:
            return False, None
        
        btc_close = btc_data['Close']
        spy_close = spy_data['Close']
        
        # 5ì¼ ìˆ˜ìµë¥  ê³„ì‚°
        if len(btc_close) < 5 or len(spy_close) < 5:
            return False, None
        
        btc_return_5d = (float(btc_close.iloc[-1]) / float(btc_close.iloc[-5]) - 1) * 100
        spy_return_5d = (float(spy_close.iloc[-1]) / float(spy_close.iloc[-5]) - 1) * 100
        
        # RISK_OFF_WARNING ì²´í¬
        if btc_return_5d <= -10.0 and spy_return_5d > -3.0:
            # ìƒê´€ê´€ê³„ ìƒìŠ¹ ì¶”ì„¸ í™•ì¸ (ì„ íƒì )
            correlation = self.calculate_btc_spy_correlation(btc_data, spy_data)
            if correlation > 0.3:  # ìƒê´€ê´€ê³„ê°€ ì–´ëŠ ì •ë„ ìˆìœ¼ë©´
                return True, "RISK_OFF_WARNING"
        
        # RISK_ON_SIGNAL ì²´í¬
        if btc_return_5d >= 10.0 and spy_return_5d < 3.0:
            return True, "RISK_ON_SIGNAL"
        
        return False, None
    
    def calculate_btc_gld_ratio(
        self, 
        btc_data: pd.DataFrame,
        gld_data: pd.DataFrame
    ) -> Dict:
        """
        BTC/GLD ë¹„ìœ¨ ë¶„ì„
        
        í•´ì„:
        - ë¹„ìœ¨ ìƒìŠ¹: íˆ¬ê¸°ì  ì„ í˜¸ ì¦ê°€
        - ë¹„ìœ¨ í•˜ë½: ì•ˆì „ìì‚° ì„ í˜¸
        
        Returns:
            Dict with ratio and trend
        """
        btc_empty = hasattr(btc_data, 'empty') and btc_data.empty if btc_data is not None else True
        gld_empty = hasattr(gld_data, 'empty') and gld_data.empty if gld_data is not None else True
        if btc_empty or gld_empty:
            return {
                'ratio': 0.0,
                'ratio_change_5d': 0.0,
                'ratio_change_20d': 0.0,
                'trend': 'NEUTRAL'
            }
        
        if 'Close' not in btc_data.columns or 'Close' not in gld_data.columns:
            return {
                'ratio': 0.0,
                'ratio_change_5d': 0.0,
                'ratio_change_20d': 0.0,
                'trend': 'NEUTRAL'
            }
        
        btc_close = btc_data['Close']
        gld_close = gld_data['Close']
        
        # ê³µí†µ ì¸ë±ìŠ¤
        common_index = btc_close.index.intersection(gld_close.index)
        if len(common_index) == 0:
            return {
                'ratio': 0.0,
                'ratio_change_5d': 0.0,
                'ratio_change_20d': 0.0,
                'trend': 'NEUTRAL'
            }
        
        # ë¹„ìœ¨ ê³„ì‚°
        ratio_series = btc_close.loc[common_index] / gld_close.loc[common_index]
        
        if len(ratio_series) == 0:
            return {
                'ratio': 0.0,
                'ratio_change_5d': 0.0,
                'ratio_change_20d': 0.0,
                'trend': 'NEUTRAL'
            }
        
        current_ratio = float(ratio_series.iloc[-1])
        
        # 5ì¼/20ì¼ ë³€í™”ìœ¨
        if len(ratio_series) >= 5:
            ratio_change_5d = (current_ratio / float(ratio_series.iloc[-5]) - 1) * 100
        else:
            ratio_change_5d = 0.0
        
        if len(ratio_series) >= 20:
            ratio_change_20d = (current_ratio / float(ratio_series.iloc[-20]) - 1) * 100
        else:
            ratio_change_20d = 0.0
        
        # ì¶”ì„¸ íŒë‹¨
        if ratio_change_5d > 5.0:
            trend = 'RISING'  # íˆ¬ê¸°ì  ì„ í˜¸ ì¦ê°€
        elif ratio_change_5d < -5.0:
            trend = 'FALLING'  # ì•ˆì „ìì‚° ì„ í˜¸
        else:
            trend = 'NEUTRAL'
        
        return {
            'ratio': current_ratio,
            'ratio_change_5d': ratio_change_5d,
            'ratio_change_20d': ratio_change_20d,
            'trend': trend
        }
    
    def calculate_risk_contribution(self, correlation_regime: str) -> float:
        """
        ì „ì²´ ìœ„í—˜ë„ì— ê¸°ì—¬í•˜ëŠ” ë¹„ì¤‘ ê²°ì •
        
        ìƒê´€ê´€ê³„ê°€ ë†’ì„ìˆ˜ë¡ (ìœ„ê¸° ì‹œ) ê¸°ì—¬ë„ ì¦ê°€
        
        Returns:
            float: ìœ„í—˜ ê¸°ì—¬ë„ (0-0.2, ì¦‰ 0-20%)
        """
        return self.RISK_CONTRIBUTION.get(correlation_regime, 0.05)
    
    def generate_interpretation(
        self,
        sentiment_score: float,
        sentiment_level: str,
        correlation: float,
        correlation_regime: str,
        is_leading: bool,
        leading_signal: Optional[str],
        risk_contribution: float,
        causality_analysis: Dict = None
    ) -> str:
        """
        ë¶„ì„ ê²°ê³¼ í•´ì„ í…ìŠ¤íŠ¸ ìƒì„±
        
        Returns:
            str: í•´ì„ í…ìŠ¤íŠ¸
        """
        if causality_analysis is None:
            causality_analysis = {}
        
        base_text = f"ì•”í˜¸í™”í ì‹œì¥ ì‹¬ë¦¬ëŠ” {sentiment_level} ìƒíƒœì…ë‹ˆë‹¤ (ì ìˆ˜: {sentiment_score:.1f}). "
        
        # ìƒê´€ê´€ê³„ í•´ì„
        if correlation_regime == "DECOUPLED":
            base_text += f"BTC-ì£¼ì‹ ìƒê´€ê´€ê³„ê°€ ë‚®ìŠµë‹ˆë‹¤ ({correlation:.2f}). ë…ìì  ì›€ì§ì„ì´ ê´€ì°°ë©ë‹ˆë‹¤. "
        elif correlation_regime == "COUPLED":
            base_text += f"BTC-ì£¼ì‹ ìƒê´€ê´€ê³„ê°€ ë³´í†µì…ë‹ˆë‹¤ ({correlation:.2f}). ì¼ë¶€ ì—°ë™ì´ ê´€ì°°ë©ë‹ˆë‹¤. "
        else:  # CRISIS_COUPLED
            base_text += f"âš ï¸ BTC-ì£¼ì‹ ìƒê´€ê´€ê³„ê°€ ë†’ìŠµë‹ˆë‹¤ ({correlation:.2f}). ìœ„ê¸° ë™ì¡°í™”ê°€ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. "
        
        # Granger Causality ì¸ê³¼ê´€ê³„ í•´ì„
        if causality_analysis and causality_analysis.get('relationship') != 'NO_CAUSALITY':
            relationship = causality_analysis.get('relationship', 'NO_CAUSALITY')
            x_to_y_pvalue = causality_analysis.get('x_to_y_pvalue', 1.0)
            y_to_x_pvalue = causality_analysis.get('y_to_x_pvalue', 1.0)
            optimal_lag = causality_analysis.get('optimal_lag', 0)
            
            if relationship == "X_LEADS":
                base_text += f"ğŸ“Š Granger Causality ê²€ì • ê²°ê³¼: BTCê°€ SPYë¥¼ ì„ í–‰í•©ë‹ˆë‹¤ (p={x_to_y_pvalue:.3f}, ì‹œì°¨ {optimal_lag}ì¼). "
            elif relationship == "Y_LEADS":
                base_text += f"ğŸ“Š Granger Causality ê²€ì • ê²°ê³¼: SPYê°€ BTCë¥¼ ì„ í–‰í•©ë‹ˆë‹¤ (p={y_to_x_pvalue:.3f}, ì‹œì°¨ {optimal_lag}ì¼). "
            elif relationship == "BIDIRECTIONAL":
                base_text += f"ğŸ“Š Granger Causality ê²€ì • ê²°ê³¼: BTCì™€ SPYê°€ ì–‘ë°©í–¥ ì¸ê³¼ê´€ê³„ë¥¼ ë³´ì…ë‹ˆë‹¤ (BTCâ†’SPY: p={x_to_y_pvalue:.3f}, SPYâ†’BTC: p={y_to_x_pvalue:.3f}). "
        
        # ì„ í–‰ì§€í‘œ í•´ì„
        if is_leading and leading_signal:
            if leading_signal == "RISK_OFF_WARNING":
                base_text += "ğŸš¨ BTCê°€ ì£¼ì‹ë³´ë‹¤ ë¨¼ì € í•˜ë½í•˜ê³  ìˆì–´ ìœ„í—˜ íšŒí”¼ ì‹ í˜¸ë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
            elif leading_signal == "RISK_ON_SIGNAL":
                base_text += "BTCê°€ ì£¼ì‹ë³´ë‹¤ ë¨¼ì € ìƒìŠ¹í•˜ê³  ìˆì–´ ìœ„í—˜ ì„ í˜¸ ì‹ í˜¸ë¡œ ì‘ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
        
        # ìœ„í—˜ ê¸°ì—¬ë„ í•´ì„
        if risk_contribution >= 0.15:
            base_text += f"ì „ì²´ ìœ„í—˜ë„ì— {risk_contribution*100:.0f}% ê¸°ì—¬í•˜ê³  ìˆì–´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        elif risk_contribution >= 0.10:
            base_text += f"ì „ì²´ ìœ„í—˜ë„ì— {risk_contribution*100:.0f}% ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤."
        else:
            base_text += f"ë…ìì  ì‹ í˜¸ë¡œ í•´ì„ë©ë‹ˆë‹¤ (ìœ„í—˜ ê¸°ì—¬ë„ {risk_contribution*100:.0f}%)."
        
        return base_text
    
    def analyze(
        self,
        btc_data: pd.DataFrame,
        spy_data: pd.DataFrame,
        gld_data: pd.DataFrame
    ) -> CryptoSentimentResult:
        """
        ì „ì²´ ë¶„ì„ ì‹¤í–‰
        
        Args:
            btc_data: BTC-USD ê°€ê²© ë°ì´í„°
            spy_data: SPY ê°€ê²© ë°ì´í„° (ìƒê´€ê´€ê³„ ê³„ì‚°ìš©)
            gld_data: GLD ê°€ê²© ë°ì´í„° (BTC/GLD ë¹„ìœ¨ìš©)
        
        Returns:
            CryptoSentimentResult ê°ì²´
        """
        # ì‹¬ë¦¬ ì ìˆ˜ ê³„ì‚°
        sentiment_score, sentiment_level = self.calculate_sentiment_score(btc_data)
        
        # BTC-SPY ìƒê´€ê´€ê³„ ê³„ì‚°
        correlation = self.calculate_btc_spy_correlation(btc_data, spy_data)
        
        # ìƒê´€ê´€ê³„ ë ˆì§ íŒë‹¨
        correlation_regime = self.determine_correlation_regime(correlation)
        
        # Granger Causality ê²€ì • (ì¸ê³¼ê´€ê³„ ë°©í–¥ì„± íŒŒì•…)
        causality_analysis = {}
        btc_empty = hasattr(btc_data, 'empty') and btc_data.empty if btc_data is not None else True
        spy_empty = hasattr(spy_data, 'empty') and spy_data.empty if spy_data is not None else True
        if not btc_empty and not spy_empty:
            if 'Close' in btc_data.columns and 'Close' in spy_data.columns:
                # ìˆ˜ìµë¥  ê³„ì‚°
                btc_returns = btc_data['Close'].pct_change().dropna()
                spy_returns = spy_data['Close'].pct_change().dropna()
                
                # ê³µí†µ ì¸ë±ìŠ¤ë¡œ ì •ë ¬
                common_index = btc_returns.index.intersection(spy_returns.index)
                if len(common_index) >= 30:  # ìµœì†Œ 30ì¼ ë°ì´í„° í•„ìš”
                    btc_aligned = btc_returns.loc[common_index]
                    spy_aligned = spy_returns.loc[common_index]
                    
                    # Granger Causality ê²€ì • ìˆ˜í–‰
                    causality_analysis = self.calculate_granger_causality(
                        series_x=btc_aligned,  # BTCê°€ ì›ì¸ í›„ë³´
                        series_y=spy_aligned,  # SPYê°€ ê²°ê³¼ í›„ë³´
                        max_lag=5
                    )
        
        # ì„ í–‰ì§€í‘œ ì²´í¬
        is_leading, leading_signal = self.check_leading_indicator(btc_data, spy_data)
        
        # ìœ„í—˜ ê¸°ì—¬ë„ ê³„ì‚°
        risk_contribution = self.calculate_risk_contribution(correlation_regime)
        
        # BTC/GLD ë¹„ìœ¨ ë¶„ì„
        btc_gld_ratio = self.calculate_btc_gld_ratio(btc_data, gld_data)
        
        # ëª¨ë©˜í…€ ê³„ì‚°
        momentum = self.calculate_btc_momentum(btc_data)
        
        # êµ¬ì„±ìš”ì†Œ í†µí•©
        components = {
            **momentum,
            'btc_gld_ratio': btc_gld_ratio,
            'correlation': correlation,
            'causality_analysis': causality_analysis,
        }
        
        # í•´ì„ í…ìŠ¤íŠ¸ ìƒì„±
        interpretation = self.generate_interpretation(
            sentiment_score,
            sentiment_level,
            correlation,
            correlation_regime,
            is_leading,
            leading_signal,
            risk_contribution,
            causality_analysis
        )
        
        return CryptoSentimentResult(
            timestamp=datetime.now().isoformat(),
            sentiment_score=sentiment_score,
            sentiment_level=sentiment_level,
            btc_spy_correlation=correlation,
            correlation_regime=correlation_regime,
            is_leading_indicator=is_leading,
            leading_signal=leading_signal,
            risk_contribution=risk_contribution,
            components=components,
            interpretation=interpretation,
            causality_analysis=causality_analysis
        )

# critical_path_analyzer.py íŒŒì¼ ëì— ì¶”ê°€

