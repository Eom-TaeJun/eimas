#!/usr/bin/env python3
"""
Schema-Driven JSON to Markdown Renderer
========================================
Automatically converts EIMAS JSON output to Markdown without hardcoding.

Architecture:
1. normalize(raw_json) -> ReportModel (standard structure)
2. render_md(ReportModel) -> Markdown

Features:
- Section-driven: renders only what exists in JSON
- Auto-generates tables from list-of-objects
- Handles unknown fields in extra_fields section
- Validates output against input
"""

import json
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, field


# ============================================================================
# SECTION SCHEMA DEFINITION
# ============================================================================

SECTION_SCHEMA = {
    # Priority determines rendering order (lower = first)
    "decision_policy": {"priority": 1, "title": "ðŸ’¡ ì˜ì‚¬ê²°ì • ì •ì±…", "icon": "ðŸ’¡"},
    "score_definitions": {"priority": 2, "title": "ðŸ“Š ë¦¬ìŠ¤í¬ ì ìˆ˜ ì •ì˜", "icon": "ðŸ“Š"},
    "allocation": {"priority": 3, "title": "ðŸ“ˆ í¬íŠ¸í´ë¦¬ì˜¤ ë°°ë¶„", "icon": "ðŸ“ˆ"},
    "portfolio_weights": {"priority": 3.5, "title": "âš–ï¸ í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘", "icon": "âš–ï¸"},
    "constraint_repair": {"priority": 4, "title": "ðŸ”§ ì œì•½ì¡°ê±´ ìˆ˜ì •", "icon": "ðŸ”§"},
    "rebalance_plan": {"priority": 5, "title": "âš–ï¸ ë¦¬ë°¸ëŸ°ì‹± ê³„íš", "icon": "âš–ï¸"},
    "hold_policy": {"priority": 6, "title": "ðŸ›‘ HOLD ì •ì±…", "icon": "ðŸ›‘"},
    "signal_hierarchy": {"priority": 7, "title": "ðŸ“¡ ì‹œê·¸ë„ ê³„ì¸µ", "icon": "ðŸ“¡"},
    "integrated_signals": {"priority": 8, "title": "ðŸ”— í†µí•© ì‹œê·¸ë„", "icon": "ðŸ”—"},
    "fomc_analysis": {"priority": 10, "title": "ðŸ¦ FOMC ë¶„ì„", "icon": "ðŸ¦"},
    "fred_summary": {"priority": 11, "title": "ðŸ›ï¸ ê±°ì‹œê²½ì œ ì§€í‘œ", "icon": "ðŸ›ï¸"},
    "regime": {"priority": 12, "title": "ðŸ“ˆ ì‹œìž¥ ë ˆì§", "icon": "ðŸ“ˆ"},
    "debate_consensus": {"priority": 13, "title": "ðŸ¤– AI í† ë¡  í•©ì˜", "icon": "ðŸ¤–"},
    "debate_results": {"priority": 13.5, "title": "ðŸ’¬ í† ë¡  ê²°ê³¼", "icon": "ðŸ’¬"},
    "validation_loop_result": {"priority": 14, "title": "âœ… ê²€ì¦ ë£¨í”„", "icon": "âœ…"},
    "verification": {"priority": 15, "title": "ðŸ” ê²€ì¦ ê²°ê³¼", "icon": "ðŸ”"},
    "market_quality": {"priority": 16, "title": "ðŸŽ¯ ì‹œìž¥ í’ˆì§ˆ", "icon": "ðŸŽ¯"},
    "bubble_risk": {"priority": 17, "title": "ðŸ’¥ ë²„ë¸” ë¦¬ìŠ¤í¬", "icon": "ðŸ’¥"},
    "genius_act_regime": {"priority": 18, "title": "ðŸ’§ Genius Act ë ˆì§", "icon": "ðŸ’§"},
    "genius_act_signals": {"priority": 18.5, "title": "ðŸ’§ Genius Act ì‹œê·¸ë„", "icon": "ðŸ’§"},
    "theme_etf_analysis": {"priority": 19, "title": "ðŸŽ¨ í…Œë§ˆ ETF", "icon": "ðŸŽ¨"},
    "etf_flow_result": {"priority": 19.5, "title": "ðŸ“Š ETF í”Œë¡œìš°", "icon": "ðŸ“Š"},
    "shock_propagation": {"priority": 20, "title": "ðŸŒŠ ì¶©ê²© ì „íŒŒ", "icon": "ðŸŒŠ"},
    "ark_analysis": {"priority": 21, "title": "ðŸš€ ARK Invest", "icon": "ðŸš€"},
    "sentiment_analysis": {"priority": 22, "title": "ðŸ˜Š ì„¼í‹°ë¨¼íŠ¸", "icon": "ðŸ˜Š"},
    "extended_data": {"priority": 22.5, "title": "ðŸ“Š í™•ìž¥ ë°ì´í„°", "icon": "ðŸ“Š"},
    "events_detected": {"priority": 23, "title": "ðŸ“… ì´ë²¤íŠ¸ íƒì§€", "icon": "ðŸ“…"},
    "event_tracking": {"priority": 23.5, "title": "ðŸ“… ì´ë²¤íŠ¸ ì¶”ì ", "icon": "ðŸ“…"},
    "tracked_events": {"priority": 23.6, "title": "ðŸ“… ì¶”ì  ì¤‘ ì´ë²¤íŠ¸", "icon": "ðŸ“…"},
    "event_predictions": {"priority": 23.7, "title": "ðŸ”® ì´ë²¤íŠ¸ ì˜ˆì¸¡", "icon": "ðŸ”®"},
    "event_attributions": {"priority": 23.8, "title": "ðŸŽ¯ ì´ë²¤íŠ¸ ê·€ì¸", "icon": "ðŸŽ¯"},
    "event_backtest_results": {"priority": 23.9, "title": "ðŸ“ˆ ì´ë²¤íŠ¸ ë°±í…ŒìŠ¤íŠ¸", "icon": "ðŸ“ˆ"},
    "volume_anomalies": {"priority": 24, "title": "ðŸ“Š ê±°ëž˜ëŸ‰ ì´ìƒ", "icon": "ðŸ“Š"},
    "critical_path_monitoring": {"priority": 25, "title": "ðŸ›¤ï¸ í¬ë¦¬í‹°ì»¬ íŒ¨ìŠ¤", "icon": "ðŸ›¤ï¸"},
    "correlation_matrix": {"priority": 26, "title": "ðŸ”— ìƒê´€ê´€ê³„ í–‰ë ¬", "icon": "ðŸ”—"},
    "correlation_tickers": {"priority": 26.5, "title": "ðŸ“Š ìƒê´€ê´€ê³„ í‹°ì»¤", "icon": "ðŸ“Š"},
    "adaptive_portfolios": {"priority": 27, "title": "ðŸŽ¯ ì ì‘í˜• í¬íŠ¸í´ë¦¬ì˜¤", "icon": "ðŸŽ¯"},
    "crypto_monitoring": {"priority": 28, "title": "â‚¿ í¬ë¦½í†  ëª¨ë‹ˆí„°ë§", "icon": "â‚¿"},
    "crypto_stress_test": {"priority": 28.5, "title": "âš ï¸ í¬ë¦½í†  ìŠ¤íŠ¸ë ˆìŠ¤", "icon": "âš ï¸"},
    "defi_tvl": {"priority": 29, "title": "ðŸ¦ DeFi TVL", "icon": "ðŸ¦"},
    "onchain_risk_signals": {"priority": 29.5, "title": "â›“ï¸ ì˜¨ì²´ì¸ ë¦¬ìŠ¤í¬", "icon": "â›“ï¸"},
    "mena_markets": {"priority": 30, "title": "ðŸŒ MENA ì‹œìž¥", "icon": "ðŸŒ"},
    "intraday_summary": {"priority": 31, "title": "â° ì¼ì¤‘ ìš”ì•½", "icon": "â°"},
    "news_correlations": {"priority": 32, "title": "ðŸ“° ë‰´ìŠ¤ ìƒê´€ê´€ê³„", "icon": "ðŸ“°"},
    "ai_report": {"priority": 40, "title": "ðŸ¤– AI ë¦¬í¬íŠ¸", "icon": "ðŸ¤–"},
    "agent_outputs": {"priority": 41, "title": "ðŸ¤– ì—ì´ì „íŠ¸ ì¶œë ¥", "icon": "ðŸ¤–"},
    "reasoning_chain": {"priority": 42, "title": "ðŸ§  ì¶”ë¡  ì²´ì¸", "icon": "ðŸ§ "},
    "devils_advocate_arguments": {"priority": 43, "title": "ðŸ˜ˆ ë°˜ëŒ€ ë…¼ê±°", "icon": "ðŸ˜ˆ"},
    "dissent_records": {"priority": 44, "title": "âš ï¸ ì´ê²¬ ê¸°ë¡", "icon": "âš ï¸"},
    "trade_plan": {"priority": 50, "title": "ðŸ“ ê±°ëž˜ ê³„íš", "icon": "ðŸ“"},
    "audit_metadata": {"priority": 99, "title": "ðŸ“‹ ê°ì‚¬ ë©”íƒ€ë°ì´í„°", "icon": "ðŸ“‹"},
}

# Table column ordering preferences
TABLE_COLUMN_ORDER = [
    "ticker", "asset", "asset_class",
    "current_weight", "target_weight", "delta_weight", "delta_pct",
    "action", "priority", "estimated_cost",
    "value", "signal", "regime", "type",
    "source", "confidence", "timestamp"
]


# ============================================================================
# DATA MODEL
# ============================================================================

@dataclass
class ReportModel:
    """Normalized report structure"""
    schema_version: str
    timestamp: str

    # Core sections (ordered by priority)
    sections: Dict[str, Any] = field(default_factory=dict)

    # Metadata
    final_recommendation: Optional[str] = None
    confidence: Optional[float] = None
    risk_score: Optional[float] = None

    # Extra fields not in schema
    extra_fields: Dict[str, Any] = field(default_factory=dict)


# ============================================================================
# NORMALIZATION LAYER
# ============================================================================

def normalize(raw_json: Dict[str, Any]) -> ReportModel:
    """
    Convert raw JSON to normalized ReportModel

    Strategy:
    1. Extract known sections from SECTION_SCHEMA
    2. Store everything else in extra_fields
    3. Preserve metadata for validation
    """
    schema_version = raw_json.get('schema_version', '1.0.0')
    timestamp = raw_json.get('timestamp', datetime.now().isoformat())

    sections = {}
    extra_fields = {}

    # Metadata fields (handled separately, not in extra)
    metadata_fields = {
        'timestamp', 'schema_version', 'final_recommendation',
        'confidence', 'risk_score', 'risk_level',
        'market_data_count', 'crypto_data_count',
        'liquidity_signal', 'has_strong_dissent',
        'full_mode_position', 'reference_mode_position', 'modes_agree',
        'warnings', 'realtime_signals',
        'whitening_summary', 'fact_check_grade',
        'base_risk_score', 'microstructure_adjustment',
        'bubble_risk_adjustment', 'extended_data_adjustment',
        'hrp_allocation_rationale', 'volume_analysis_summary'
    }

    # Extract known sections
    for key, value in raw_json.items():
        if key in SECTION_SCHEMA:
            sections[key] = value
        elif key in metadata_fields:
            # Metadata - handled separately
            continue
        else:
            # Unknown field - will be rendered in extra section
            extra_fields[key] = value

    # Handle nested operational_report
    if 'operational_report' in raw_json:
        op_report = raw_json['operational_report']
        if isinstance(op_report, dict):
            for key, value in op_report.items():
                if key in SECTION_SCHEMA:
                    sections[key] = value
                else:
                    extra_fields[f'operational_report.{key}'] = value

    return ReportModel(
        schema_version=schema_version,
        timestamp=timestamp,
        sections=sections,
        final_recommendation=raw_json.get('final_recommendation'),
        confidence=raw_json.get('confidence'),
        risk_score=raw_json.get('risk_score'),
        extra_fields=extra_fields
    )


# ============================================================================
# RENDERING UTILITIES
# ============================================================================

def format_value(value: Any, key: str = "") -> str:
    """Format a value for markdown display"""
    if value is None:
        return "N/A"
    elif isinstance(value, bool):
        return "ì˜ˆ" if value else "ì•„ë‹ˆì˜¤"
    elif isinstance(value, float):
        # Smart formatting based on key name
        if 'weight' in key or 'ratio' in key or 'confidence' in key:
            return f"{value * 100:.2f}%" if value <= 1 else f"{value:.2f}"
        elif 'score' in key or 'risk' in key:
            return f"{value:.2f}"
        else:
            return f"{value:.4f}"
    elif isinstance(value, (int)):
        return str(value)
    elif isinstance(value, str):
        return value
    elif isinstance(value, list):
        return f"{len(value)} items"
    elif isinstance(value, dict):
        return f"{len(value)} fields"
    else:
        return str(value)


def auto_table(data: List[Dict[str, Any]], max_rows: int = 20) -> str:
    """
    Auto-generate markdown table from list of objects

    Strategy:
    1. Collect all unique keys
    2. Order by TABLE_COLUMN_ORDER preference
    3. Generate table with max_rows limit
    """
    if not data or not isinstance(data, list) or not isinstance(data[0], dict):
        return ""

    # Collect all unique keys
    all_keys = set()
    for item in data:
        if isinstance(item, dict):
            all_keys.update(item.keys())

    # Order keys by preference
    ordered_keys = []
    for pref_key in TABLE_COLUMN_ORDER:
        if pref_key in all_keys:
            ordered_keys.append(pref_key)
            all_keys.remove(pref_key)
    # Add remaining keys
    ordered_keys.extend(sorted(all_keys))

    # Build table
    lines = []

    # Header
    header = "| " + " | ".join(ordered_keys) + " |"
    separator = "|" + "|".join(["---" for _ in ordered_keys]) + "|"
    lines.append(header)
    lines.append(separator)

    # Rows
    for item in data[:max_rows]:
        if isinstance(item, dict):
            row_values = [format_value(item.get(k), k) for k in ordered_keys]
            row = "| " + " | ".join(row_values) + " |"
            lines.append(row)

    if len(data) > max_rows:
        lines.append(f"| ... | ({len(data) - max_rows}ê°œ ìƒëžµ) |")

    return "\n".join(lines)


def render_value(value: Any, key: str = "", indent: int = 0) -> List[str]:
    """
    Recursively render a value to markdown lines

    Strategy:
    - dict -> nested list
    - list of dicts -> table
    - list of primitives -> bullet list
    - primitive -> formatted value
    """
    prefix = "  " * indent
    lines = []

    if isinstance(value, dict):
        for k, v in value.items():
            if isinstance(v, (dict, list)):
                lines.append(f"{prefix}- **{k}:**")
                lines.extend(render_value(v, k, indent + 1))
            else:
                formatted = format_value(v, k)
                lines.append(f"{prefix}- **{k}:** {formatted}")

    elif isinstance(value, list):
        if not value:
            return [f"{prefix}(empty)"]

        # Check if list of dicts -> table
        if all(isinstance(item, dict) for item in value):
            table = auto_table(value)
            if table:
                lines.append(table)
            else:
                # Fallback to nested rendering
                for i, item in enumerate(value[:10]):
                    lines.append(f"{prefix}- Item {i+1}:")
                    lines.extend(render_value(item, "", indent + 1))
                if len(value) > 10:
                    lines.append(f"{prefix}  ... ({len(value) - 10}ê°œ ìƒëžµ)")
        else:
            # List of primitives
            for item in value[:20]:
                lines.append(f"{prefix}- {format_value(item, key)}")
            if len(value) > 20:
                lines.append(f"{prefix}  ... ({len(value) - 20}ê°œ ìƒëžµ)")

    else:
        lines.append(f"{prefix}{format_value(value, key)}")

    return lines


def render_section(section_key: str, section_data: Any) -> str:
    """Render a single section to markdown"""
    schema = SECTION_SCHEMA.get(section_key, {})
    title = schema.get('title', section_key)

    lines = [f"## {title}", ""]

    # Render content
    content_lines = render_value(section_data, section_key)
    lines.extend(content_lines)

    return "\n".join(lines)


# ============================================================================
# MAIN RENDERER
# ============================================================================

def render_md(model: ReportModel) -> str:
    """
    Render ReportModel to Markdown

    Strategy:
    1. Header with metadata
    2. Executive summary
    3. Sections in priority order
    4. Extra fields
    5. Footer with validation
    """
    parts = []

    # ========== HEADER ==========
    ts = model.timestamp[:19].replace('T', ' ')
    parts.append(f"# ðŸ“Š EIMAS ë¶„ì„ ë¦¬í¬íŠ¸")
    parts.append(f"\n**ìƒì„± ì‹œê°„:** {ts}")
    parts.append(f"**ìŠ¤í‚¤ë§ˆ ë²„ì „:** {model.schema_version}")

    # ========== EXECUTIVE SUMMARY ==========
    if model.final_recommendation or model.risk_score:
        parts.append("\n---\n")
        parts.append("## ðŸ“‹ Executive Summary")
        parts.append("")

        if model.final_recommendation:
            parts.append(f"**ìµœì¢… ê¶Œê³ :** {model.final_recommendation}")
        if model.confidence:
            parts.append(f"**ì‹ ë¢°ë„:** {model.confidence * 100:.1f}%")
        if model.risk_score:
            parts.append(f"**ë¦¬ìŠ¤í¬ ì ìˆ˜:** {model.risk_score:.2f}/100")

    # ========== SECTIONS (by priority) ==========
    # Sort sections by priority
    sorted_sections = sorted(
        model.sections.items(),
        key=lambda x: SECTION_SCHEMA.get(x[0], {}).get('priority', 999)
    )

    for section_key, section_data in sorted_sections:
        if section_data:  # Only render non-empty sections
            parts.append("\n---\n")
            parts.append(render_section(section_key, section_data))

    # ========== EXTRA FIELDS ==========
    if model.extra_fields:
        parts.append("\n---\n")
        parts.append("## ðŸ—‚ï¸ Additional Fields")
        parts.append("")
        parts.append("*Fields not in standard schema:*")
        parts.append("")

        for key, value in sorted(model.extra_fields.items())[:30]:
            if isinstance(value, (dict, list)):
                parts.append(f"\n### {key}")
                parts.extend(render_value(value, key))
            else:
                parts.append(f"- **{key}:** {format_value(value, key)}")

        if len(model.extra_fields) > 30:
            parts.append(f"\n*... ({len(model.extra_fields) - 30}ê°œ í•„ë“œ ìƒëžµ)*")

    # ========== FOOTER ==========
    parts.append("\n---\n")
    parts.append("## âš ï¸ Disclaimer")
    parts.append("")
    parts.append("ë³¸ ë¦¬í¬íŠ¸ëŠ” EIMAS ì‹œìŠ¤í…œì— ì˜í•´ ìžë™ ìƒì„±ë˜ì—ˆìœ¼ë©°, íˆ¬ìž ê¶Œìœ ê°€ ì•„ë‹™ë‹ˆë‹¤.")
    parts.append("ëª¨ë“  íˆ¬ìž ê²°ì •ì€ ë³¸ì¸ì˜ íŒë‹¨ê³¼ ì±…ìž„ í•˜ì— ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤.")
    parts.append("")
    parts.append("---")
    parts.append("*Generated by EIMAS Schema-Driven Renderer v2.0*")

    return "\n".join(parts)


# ============================================================================
# VALIDATION
# ============================================================================

def validate_output(raw_json: Dict[str, Any], markdown: str) -> List[str]:
    """
    Validate that markdown output matches input

    Returns list of validation errors (empty = success)
    """
    errors = []

    # Check 1: Final recommendation matches
    final_rec = raw_json.get('final_recommendation')
    if final_rec and final_rec not in markdown:
        errors.append(f"Final recommendation '{final_rec}' not found in markdown")

    # Check 2: Decision policy stance matches final recommendation
    op_report = raw_json.get('operational_report', {})
    decision_policy = op_report.get('decision_policy', {})
    policy_stance = decision_policy.get('final_stance')

    if policy_stance and final_rec and policy_stance != final_rec:
        errors.append(f"Stance mismatch: decision_policy={policy_stance}, final_recommendation={final_rec}")

    # Check 3: Risk score present
    risk_score = raw_json.get('risk_score')
    if risk_score is not None and str(risk_score) not in markdown:
        errors.append(f"Risk score {risk_score} not found in markdown")

    return errors


# ============================================================================
# MAIN ENTRY POINT
# ============================================================================

def convert_json_to_md(json_path: Path) -> Path:
    """Convert JSON file to Markdown using schema-driven renderer"""

    # Load JSON
    with open(json_path, 'r', encoding='utf-8') as f:
        raw_json = json.load(f)

    # Normalize
    model = normalize(raw_json)

    # Render
    markdown = render_md(model)

    # Validate
    errors = validate_output(raw_json, markdown)
    if errors:
        print("âš ï¸  Validation warnings:")
        for err in errors:
            print(f"  - {err}")

    # Save
    md_path = json_path.with_suffix('.md')
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(markdown)

    # Stats
    json_size = len(json.dumps(raw_json))
    md_size = len(markdown)
    coverage = (md_size / json_size) * 100 if json_size > 0 else 0

    print(f"âœ“ Converted: {json_path.name} â†’ {md_path.name}")
    print(f"  JSON: {json_size:,} bytes, MD: {md_size:,} bytes")
    print(f"  Coverage: {coverage:.1f}%")
    print(f"  Sections: {len(model.sections)}")
    print(f"  Extra fields: {len(model.extra_fields)}")

    return md_path


def main():
    """Main entry point"""
    output_dir = Path(__file__).parent.parent / "outputs"

    if len(sys.argv) > 1:
        # Specific file
        json_path = output_dir / sys.argv[1]
    else:
        # Latest eimas_*.json
        json_files = sorted(output_dir.glob("eimas_*.json"), reverse=True)
        if not json_files:
            print("No eimas_*.json files found in outputs/")
            return
        json_path = json_files[0]

    if not json_path.exists():
        print(f"File not found: {json_path}")
        return

    convert_json_to_md(json_path)


if __name__ == "__main__":
    main()
