#!/usr/bin/env python3
"""
EIMAS ì „ì²´ ë¶„ì„ ì‹¤í–‰ (ì‹¤ì œ ì‹œì¥ ë°ì´í„°)
======================================
2026-01-25 í†µí•© ë²„ì „

ì‹¤í–‰í•˜ëŠ” ë¶„ì„:
- Phase 2.14: HFT ë¯¸ì„¸êµ¬ì¡°
- Phase 2.15: GARCH ë³€ë™ì„±
- Phase 2.16: ì •ë³´ í”Œë¡œìš°
- Phase 2.17: Proof-of-Index
- Phase 2.18: Systemic Similarity
- Phase 2.19: DBSCAN Outlier Detection (NEW)
- Phase 2.20: DTW Time Series Similarity (NEW)

ì‹¤ì œ ë°ì´í„°:
- yfinanceë¡œ SPY, QQQ, TLT, GLD, BTC-USD ë‹¤ìš´ë¡œë“œ
- ìµœê·¼ 1ë…„ ë°ì´í„° ì‚¬ìš©
"""

import sys
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("EIMAS ì „ì²´ ë¶„ì„ ì‹¤í–‰ (ì‹¤ì œ ì‹œì¥ ë°ì´í„°)")
print("=" * 80)
print(f"ì‹¤í–‰ ì‹œê°: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)


# ============================================================================
# ì‹¤ì œ ì‹œì¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
# ============================================================================

def download_market_data():
    """yfinanceë¡œ ì‹¤ì œ ì‹œì¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    print("\n[0] Downloading real market data...")

    try:
        import yfinance as yf
    except ImportError:
        print("   âŒ yfinance not installed. Installing...")
        import subprocess
        subprocess.check_call([sys.executable, "-m", "pip", "install", "yfinance", "-q"])
        import yfinance as yf

    # ë‹¤ìš´ë¡œë“œí•  í‹°ì»¤
    tickers = [
        'SPY',    # S&P 500
        'QQQ',    # Nasdaq 100
        'TLT',    # 20Y Treasury
        'GLD',    # Gold
        'BTC-USD', # Bitcoin
        'IWM',    # Russell 2000
        'EFA',    # EAFE
        'EEM',    # Emerging Markets
        'HYG',    # High Yield Corporate
        'LQD',    # Investment Grade Corporate
    ]

    # ê¸°ê°„: ìµœê·¼ 1ë…„
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)

    market_data = {}

    for ticker in tickers:
        try:
            print(f"   Downloading {ticker}...", end=" ")
            df = yf.download(ticker, start=start_date, end=end_date, progress=False)

            if not df.empty:
                market_data[ticker] = df
                print(f"âœ“ ({len(df)} days)")
            else:
                print(f"âš ï¸ No data")
        except Exception as e:
            print(f"âŒ Error: {e}")

    print(f"\n   âœ… Downloaded {len(market_data)} tickers")
    print(f"   Period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")

    return market_data


# ============================================================================
# Phase 2.14: HFT Microstructure
# ============================================================================

def run_hft_microstructure(market_data):
    """HFT ë¯¸ì„¸êµ¬ì¡° ë¶„ì„"""
    print("\n" + "=" * 80)
    print("[Phase 2.14] HFT Microstructure Analysis")
    print("=" * 80)

    from pipeline.analyzers import analyze_hft_microstructure

    try:
        result = analyze_hft_microstructure(market_data)

        if result:
            print("\nâœ… HFT Microstructure analysis completed")

            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            if 'kyle_lambda' in result:
                print(f"\nKyle's Lambda Results:")
                for ticker, data in list(result['kyle_lambda'].items())[:3]:
                    print(f"  {ticker}: {data.get('interpretation', 'N/A')}")

            return result
        else:
            print("âš ï¸ No results")
            return {}

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return {}


# ============================================================================
# Phase 2.15: GARCH Volatility
# ============================================================================

def run_garch_volatility(market_data):
    """GARCH ë³€ë™ì„± ëª¨ë¸ë§"""
    print("\n" + "=" * 80)
    print("[Phase 2.15] GARCH Volatility Modeling")
    print("=" * 80)

    from pipeline.analyzers import analyze_volatility_garch

    try:
        result = analyze_volatility_garch(market_data)

        if result:
            print("\nâœ… GARCH volatility analysis completed")

            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            if 'models' in result:
                print(f"\nGARCH Models Fitted:")
                for ticker, data in list(result['models'].items())[:3]:
                    params = data.get('parameters', {})
                    print(f"  {ticker}: Î±={params.get('alpha', 0):.4f}, Î²={params.get('beta', 0):.4f}")

            return result
        else:
            print("âš ï¸ No results")
            return {}

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return {}


# ============================================================================
# Phase 2.16: Information Flow
# ============================================================================

def run_information_flow(market_data):
    """ì •ë³´ í”Œë¡œìš° ë¶„ì„"""
    print("\n" + "=" * 80)
    print("[Phase 2.16] Information Flow Analysis")
    print("=" * 80)

    from pipeline.analyzers import analyze_information_flow

    try:
        result = analyze_information_flow(market_data)

        if result:
            print("\nâœ… Information Flow analysis completed")

            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            if 'abnormal_volume' in result:
                ab_vol = result['abnormal_volume']
                print(f"\nAbnormal Volume Analysis:")
                print(f"  Total Abnormal Days: {ab_vol.get('total_abnormal_days', 0)}")
                print(f"  Abnormal Ratio: {ab_vol.get('abnormal_ratio', 0):.1%}")
                print(f"  Interpretation: {ab_vol.get('interpretation', 'N/A')}")

            return result
        else:
            print("âš ï¸ No results")
            return {}

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return {}


# ============================================================================
# Phase 2.17: Proof-of-Index
# ============================================================================

def run_proof_of_index(market_data):
    """Proof-of-Index ê³„ì‚°"""
    print("\n" + "=" * 80)
    print("[Phase 2.17] Proof-of-Index (Blockchain Transparency)")
    print("=" * 80)

    from pipeline.analyzers import calculate_proof_of_index

    try:
        result = calculate_proof_of_index(market_data)

        if result:
            print("\nâœ… Proof-of-Index completed")

            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            if 'index_snapshot' in result:
                snapshot = result['index_snapshot']
                print(f"\nIndex Value: ${snapshot.get('index_value', 0):,.2f}")
                print(f"Hash Verification: {result.get('verification', {}).get('is_valid', False)}")

            return result
        else:
            print("âš ï¸ No results")
            return {}

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return {}


# ============================================================================
# Phase 2.18: Systemic Similarity
# ============================================================================

def run_systemic_similarity(market_data):
    """Systemic Similarity ë¶„ì„"""
    print("\n" + "=" * 80)
    print("[Phase 2.18] Systemic Similarity Analysis")
    print("=" * 80)

    from pipeline.analyzers import enhance_portfolio_with_systemic_similarity

    try:
        result = enhance_portfolio_with_systemic_similarity(market_data)

        if result:
            print("\nâœ… Systemic Similarity completed")

            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            if 'most_similar_pair' in result:
                pair = result['most_similar_pair']
                print(f"\nMost Similar: {pair['assets'][0]} â†” {pair['assets'][1]}")
                print(f"Similarity: {pair['similarity']:.3f}")

            return result
        else:
            print("âš ï¸ No results")
            return {}

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return {}


# ============================================================================
# Phase 2.19: DBSCAN Outlier Detection (NEW)
# ============================================================================

def run_dbscan_outliers(market_data):
    """DBSCAN ì´ìƒì¹˜ íƒì§€"""
    print("\n" + "=" * 80)
    print("[Phase 2.19] DBSCAN Outlier Detection (NEW)")
    print("=" * 80)

    from pipeline.analyzers import detect_outliers_with_dbscan

    try:
        result = detect_outliers_with_dbscan(market_data)

        if result:
            print("\nâœ… DBSCAN Outlier Detection completed")

            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            print(f"\nOutliers: {result.get('n_outliers', 0)}/{result.get('n_total_assets', 0)}")
            print(f"Clusters: {result.get('n_clusters', 0)}")
            print(f"Interpretation: {result.get('interpretation', 'N/A')}")

            if result.get('outlier_tickers'):
                print(f"\nOutlier Tickers (first 5):")
                for ticker in result['outlier_tickers'][:5]:
                    print(f"  - {ticker}")

            return result
        else:
            print("âš ï¸ No results")
            return {}

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return {}


# ============================================================================
# Phase 2.20: DTW Time Series Similarity (NEW)
# ============================================================================

def run_dtw_similarity(market_data):
    """DTW ì‹œê³„ì—´ ìœ ì‚¬ë„ ë¶„ì„"""
    print("\n" + "=" * 80)
    print("[Phase 2.20] DTW Time Series Similarity (NEW)")
    print("=" * 80)

    from pipeline.analyzers import analyze_dtw_similarity

    try:
        result = analyze_dtw_similarity(market_data)

        if result:
            print("\nâœ… DTW Similarity analysis completed")

            # ì£¼ìš” ê²°ê³¼ ì¶œë ¥
            print(f"\nAssets Analyzed: {result.get('n_series', 0)}")
            print(f"Avg DTW Distance: {result.get('avg_distance', 0):.4f}")

            most_sim = result.get('most_similar_pair', {})
            if most_sim:
                print(f"\nMost Similar: {most_sim.get('asset1', 'N/A')} â†” {most_sim.get('asset2', 'N/A')}")
                print(f"DTW Distance: {most_sim.get('distance', 0):.4f}")

            # Lead-Lag ê²°ê³¼
            lead_lag = result.get('lead_lag_spy_qqq', {})
            if lead_lag:
                print(f"\nLead-Lag (SPY vs QQQ):")
                print(f"  {lead_lag.get('interpretation', 'N/A')}")

            return result
        else:
            print("âš ï¸ No results")
            return {}

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()
        return {}


# ============================================================================
# Main Execution
# ============================================================================

def main():
    """ë©”ì¸ ì‹¤í–‰"""

    # 1. ì‹œì¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
    market_data = download_market_data()

    if not market_data:
        print("\nâŒ No market data available")
        return 1

    # ê²°ê³¼ ì €ì¥
    results = {
        'timestamp': datetime.now().isoformat(),
        'tickers': list(market_data.keys()),
        'analyses': {}
    }

    # 2. ë¶„ì„ ì‹¤í–‰
    results['analyses']['hft_microstructure'] = run_hft_microstructure(market_data)
    results['analyses']['garch_volatility'] = run_garch_volatility(market_data)
    results['analyses']['information_flow'] = run_information_flow(market_data)
    results['analyses']['proof_of_index'] = run_proof_of_index(market_data)
    results['analyses']['systemic_similarity'] = run_systemic_similarity(market_data)
    results['analyses']['dbscan_outliers'] = run_dbscan_outliers(market_data)
    results['analyses']['dtw_similarity'] = run_dtw_similarity(market_data)

    # 3. ìµœì¢… ìš”ì•½
    print("\n" + "=" * 80)
    print("FINAL SUMMARY")
    print("=" * 80)

    completed = sum(1 for v in results['analyses'].values() if v)
    total = len(results['analyses'])

    print(f"\nCompleted: {completed}/{total} analyses")

    for name, data in results['analyses'].items():
        status = "âœ…" if data else "âŒ"
        print(f"{status} {name}")

    # 4. ê²°ê³¼ ì €ì¥
    import json
    from pathlib import Path

    output_dir = Path("outputs")
    output_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = output_dir / f"full_analysis_{timestamp}.json"

    # JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜
    serializable_results = {
        'timestamp': results['timestamp'],
        'tickers': results['tickers'],
        'analyses': {}
    }

    for key, value in results['analyses'].items():
        if value:
            serializable_results['analyses'][key] = {
                'completed': True,
                'summary': str(value)[:200] + '...' if len(str(value)) > 200 else str(value)
            }
        else:
            serializable_results['analyses'][key] = {'completed': False}

    with open(output_file, 'w') as f:
        json.dump(serializable_results, f, indent=2)

    print(f"\nğŸ’¾ Results saved to: {output_file}")

    print("\n" + "=" * 80)
    if completed == total:
        print("ğŸ‰ ëª¨ë“  ë¶„ì„ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        print(f"âš ï¸ {total - completed}ê°œ ë¶„ì„ ì‹¤íŒ¨")
    print("=" * 80)

    return 0 if completed == total else 1


if __name__ == "__main__":
    sys.exit(main())
